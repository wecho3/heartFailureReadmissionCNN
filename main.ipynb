{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\winsl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\winsl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General Python Libraries\n",
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]='1'\n",
    "import time\n",
    "import datetime\n",
    "import string\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "# Pandas and Numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# SKLearn\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, ShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Download resources\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) MIMIC-III Data Processing\n",
    "The MIMIC-III data is publically available through <a href=\"url\" target=\"https://physionet.org/content/mimiciii/1.4/\">PhysioNet</a>. These are the relevant tables for this paper.\n",
    "* DIAGNOSIS_ICD table\n",
    "    * ROW_ID: (INT) Unique identifier for table\n",
    "    * SUBJECT_ID: (INT) Unique identifier for patient\n",
    "    * HADM_ID: (INT) Unique identifier for admission\n",
    "    * ICD9_CODE: (VARCHAR(10)) Final diagnosis associated to patient admission\n",
    "* ADMISSIONS table\n",
    "    * ROW_ID: (INT) Unique identifier for table\n",
    "    * SUBJECT_ID: (INT) Unique identifier for patient\n",
    "    * HADM_ID: (INT) Unique identifier for admission\n",
    "    * ADMITTIME: (TIMESTAMP(0)) Admit time for admission\n",
    "    * DISCHTIME: (TIMESTAMP(0)) Discharge time for admission\n",
    "* NOTEEVENTS table\n",
    "    * ROW_ID: (INT) Unique identifier for table\n",
    "    * SUBJECT_ID: (INT) Unique identifier for patient\n",
    "    * HADM_ID: (INT) Unique identifier for admission\n",
    "    * CATEGORY: (VARCHAR(50)) Type of note recorded ('Discharge summary' for discharge summary notes)\n",
    "    * DESCRIPTION: (VARCHAR(300)) 'Report' indicates a full note, 'Addendum' indicates additional text to be added to the previous report\n",
    "    * ISERROR: (CHAR(1)) '1' if physician indicates that the note is an error\n",
    "    * TEXT: (TEXT) Note text\n",
    "\n",
    "In addition, the paper references particular ICD-9 codes as related to heart failure:\n",
    "*398.91, 402.01, 402.11, 402.91, 404.01, 404.03, 404.11, 404.13, 404.91, 404.93, 428.0, 428.1, 428.20, 428.21, 428.22, 428.23, 428.30, 428.31, 428.32, 428.33, 428.40, 428.41, 428.42, 428.43, 428.9*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Loading MIMIC-III Data and ICD-9 HF Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total diagnoses for admissions:  651047\n",
      "Total admissions:  58976\n",
      "Total notes for admissions:  2083180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3457: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# File paths to raw data CSV (with gz compression)\n",
    "CURR_DIRNAME = os.getcwd()\n",
    "DATA_PATH_DIAGNOSES = os.path.join(CURR_DIRNAME, r'mimic-iii-clinical-database-1.4', r'DIAGNOSES_ICD.csv.gz')\n",
    "DATA_PATH_ADMISSIONS = os.path.join(CURR_DIRNAME, r'mimic-iii-clinical-database-1.4', r'ADMISSIONS.csv.gz')\n",
    "DATA_PATH_NOTES = os.path.join(CURR_DIRNAME, r'mimic-iii-clinical-database-1.4', r'NOTEEVENTS.csv.gz')\n",
    "\n",
    "# Additional manual data\n",
    "HEART_FAILURE_ICD9 = {'39891', \n",
    "\t\t\t\t\t'40201', '40211', '40291', \n",
    "\t\t\t\t\t'40401', '40403', '40411', '40413', '40491', '40493', \n",
    "\t\t\t\t\t '4280',  '4281', '42820', '42821', '42822', '42823', '42830', '42831', '42832', '42833', '42840', '42841', '42842', '42843', '4289'}\n",
    "\n",
    "# Load CSV files\n",
    "# Load diagnoses data\n",
    "DATA_DIAGNOSES_RAW = pd.read_csv(DATA_PATH_DIAGNOSES, \n",
    "                                compression='gzip',\n",
    "                                on_bad_lines='skip')\n",
    "print(\"Total diagnoses for admissions: \", len(DATA_DIAGNOSES_RAW))\n",
    "# Load admissions data\n",
    "DATA_ADMISSIONS_RAW = pd.read_csv(DATA_PATH_ADMISSIONS, \n",
    "                                compression='gzip',\n",
    "                                on_bad_lines='skip')\n",
    "print(\"Total admissions: \", len(DATA_ADMISSIONS_RAW))\n",
    "# Load notes data\n",
    "DATA_NOTES_RAW = pd.read_csv(DATA_PATH_NOTES, \n",
    "                            compression='gzip',\n",
    "                            on_bad_lines='skip')\n",
    "print(\"Total notes for admissions: \", len(DATA_NOTES_RAW))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Retrieving All Heart Failure Admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Admissions #:  14040\n",
      "<bound method NDFrame.head of         SUBJECT_ID  HADM_ID\n",
      "51             115   114585\n",
      "67             117   140784\n",
      "150            124   138376\n",
      "211            130   198214\n",
      "321             68   108329\n",
      "...            ...      ...\n",
      "650831       97132   144063\n",
      "650866       97144   109999\n",
      "650973       97172   133092\n",
      "650995       97488   152542\n",
      "651016       97488   161999\n",
      "\n",
      "[14040 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "hf_admissions_filter = DATA_DIAGNOSES_RAW['ICD9_CODE'].map(lambda x: x in HEART_FAILURE_ICD9)\n",
    "HF_ADMISSIONS = DATA_DIAGNOSES_RAW[hf_admissions_filter][['SUBJECT_ID', 'HADM_ID']].drop_duplicates()\n",
    "\n",
    "print(\"All Admissions #: \", len(HF_ADMISSIONS))\n",
    "print(HF_ADMISSIONS.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3) Determining Readmissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1) Finding Admission Times\n",
    "The **ADMISSIONS** table contains the times of admit and discharge for each admission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF Admissions #:  14040\n",
      "HF Subjects #:  10436\n"
     ]
    }
   ],
   "source": [
    "# Find admission times (admit and discharge)\n",
    "admissions_wTimes = DATA_ADMISSIONS_RAW[['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME']].copy()\n",
    "admissions_wTimes.loc[:, 'DISCHTIME'] = admissions_wTimes['DISCHTIME'].map(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "admissions_wTimes.loc[:, 'ADMITTIME'] = admissions_wTimes['ADMITTIME'].map(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "hf_admissions_wTimes = HF_ADMISSIONS.merge(admissions_wTimes, how='left', on=['SUBJECT_ID', 'HADM_ID']).sort_values(by=['SUBJECT_ID', 'ADMITTIME'])\n",
    "hf_admissions_groupedBySubject = hf_admissions_wTimes.groupby('SUBJECT_ID')\n",
    "\n",
    "print(\"HF Admissions #: \", len(hf_admissions_wTimes))\n",
    "#print(hf_admissions_wTimes.head)\n",
    "print(\"HF Subjects #: \", len(hf_admissions_groupedBySubject))\n",
    "#print(hf_admissions_groupedBySubject.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2) Finding Time to Next Admission\n",
    "\n",
    "Time to next admission is determined by discharge time from current admission to the admit time of the subsequent admission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF Admissions # w/ Readmit:  14040\n"
     ]
    }
   ],
   "source": [
    "# Find readmissions intervals\n",
    "hf_admissions_wTimes['NEXTADMITTIME'] = hf_admissions_groupedBySubject['ADMITTIME'].shift(-1, axis=0)\n",
    "get_days = lambda x: x.components.days if hasattr(x, \"components\") else float(\"NaN\")\n",
    "hf_admissions_wTimes['READMISSIONINTERVAL'] =  (hf_admissions_wTimes['NEXTADMITTIME'] - hf_admissions_wTimes['DISCHTIME']).map(get_days)\n",
    "\n",
    "print(\"HF Admissions # w/ Readmit: \", len(hf_admissions_wTimes))\n",
    "#print(hf_admissions_wTimes.head)\n",
    "#print(hf_admissions_wTimes.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2.A) General Readmissions\n",
    "General readmissions are defined as admissions that have a subsequent admission. The length of time to the next admission is irrelevant.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF General Readmissions #:  3604\n"
     ]
    }
   ],
   "source": [
    "# Find general readmissions\n",
    "HF_GEN_READMISSIONS = hf_admissions_wTimes.copy().dropna()\n",
    "\n",
    "print(\"HF General Readmissions #: \", len(HF_GEN_READMISSIONS))\n",
    "#print(HF_GEN_READMISSIONS.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2.B) 30 Day Readmissions\n",
    "30-day readmissions are defined as admissions that have a subsequent admission with an admit time that is within 30 days of the current admissions discharge time.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF 30-Day Readmissions #:  969\n"
     ]
    }
   ],
   "source": [
    "# Find 30-day readmissions\n",
    "HF_30DAY_READMISSIONS = HF_GEN_READMISSIONS.copy()[HF_GEN_READMISSIONS['READMISSIONINTERVAL'] <= 30]\n",
    "\n",
    "print(\"HF 30-Day Readmissions #: \", len(HF_30DAY_READMISSIONS))\n",
    "#print(HF_30DAY_READMISSIONS.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4) Determining Discharge Summary Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1) Loading Discharge Summary Notes\n",
    "The notes need to meet the following criteria for inclusion:\n",
    "* The note must not be marked as an error by a provider `(ISERROR != '1')`\n",
    "* The category is discharge summary `(CATEGORY == 'Discharge summary')`\n",
    "* Only full notes are included `(DESCRIPTION == 'Report')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total discharge summary notes w/o errors:  55177\n"
     ]
    }
   ],
   "source": [
    "# Find valid discharge summary notes\n",
    "# - Remove notes marked as error by physician\n",
    "# - Only keep notes marked as Discharge Summary\n",
    "dischargeSummary_notes_view = DATA_NOTES_RAW[['SUBJECT_ID', 'HADM_ID', 'CATEGORY', 'DESCRIPTION', 'ISERROR', 'TEXT']]\n",
    "\n",
    "dischargeSummary_notes_view = dischargeSummary_notes_view[(dischargeSummary_notes_view[\"ISERROR\"] != 1) & \n",
    "                                                          (dischargeSummary_notes_view[\"CATEGORY\"] == 'Discharge summary') &\n",
    "                                                          (dischargeSummary_notes_view[\"DESCRIPTION\"] == 'Report')]\n",
    "dischargeSummary_notes = dischargeSummary_notes_view[['SUBJECT_ID', 'HADM_ID', 'TEXT']].copy()\n",
    "\n",
    "print(\"Total discharge summary notes w/o errors: \", len(dischargeSummary_notes))\n",
    "#print(dischargeSummary_notes.head)\n",
    "#print(dischargeSummary_notes['TEXT'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2) Note Text Processing\n",
    "Note text is processed in the following manner:\n",
    "1. Tokenization through NLTK\n",
    "2. Removal of stopwords in NLTK corpora\n",
    "3. Removal of punctuation from string defintion list\n",
    "4. Removal of tokens that are numeric\n",
    "5. Removal of tokens that contain a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of        SUBJECT_ID   HADM_ID                                               TEXT\n",
      "0           22532  167853.0  [admission, date, discharge, date, service, ad...\n",
      "1           13702  107527.0  [admission, date, discharge, date, date, birth...\n",
      "2           13702  167118.0  [admission, date, discharge, date, service, ca...\n",
      "3           13702  196489.0  [admission, date, discharge, date, service, me...\n",
      "4           26880  135453.0  [admission, date, discharge, date, date, birth...\n",
      "...           ...       ...                                                ...\n",
      "55970       43691  147266.0  [admission, date, discharge, date, date, birth...\n",
      "55971       80847  129802.0  [admission, date, discharge, date, date, birth...\n",
      "55972       41074  182558.0  [admission, date, discharge, date, date, birth...\n",
      "55973       76397  184741.0  [admission, date, discharge, date, date, birth...\n",
      "55974       87196  121964.0  [admission, date, discharge, date, date, birth...\n",
      "\n",
      "[55177 rows x 3 columns]>\n",
      "['admission', 'date', 'discharge', 'date', 'service', 'addendum', 'radiologic', 'studies', 'radiologic', 'studies', 'also', 'included', 'chest', 'ct', 'confirmed', 'cavitary', 'lesions', 'left', 'lung', 'apex', 'consistent', 'infectious', 'process/tuberculosis', 'also', 'moderate-sized', 'left', 'pleural', 'effusion', 'head', 'ct', 'head', 'ct', 'showed', 'intracranial', 'hemorrhage', 'mass', 'effect', 'old', 'infarction', 'consistent', 'past', 'medical', 'history', 'abdominal', 'ct', 'abdominal', 'ct', 'showed', 'lesions', 'sacrum', 'likely', 'secondary', 'osteoporosis', 'followed', 'repeat', 'imaging', 'outpatient', 'first', 'first', 'last', 'name', 'm.d', 'md', 'number', 'dictated', 'hospital', 'job', 'job', 'number']\n"
     ]
    }
   ],
   "source": [
    "# Create set of stopwords and punctuation to remove from token list\n",
    "stopwords_cache = set(stopwords.words(\"English\"))\n",
    "punctuation_cache = set(string.punctuation)\n",
    "remove_cache = stopwords_cache.union(punctuation_cache)\n",
    "\n",
    "# Tokenize note text and remove stopwords and numbers from note text\n",
    "dischargeSummary_notes_tokenized = dischargeSummary_notes.copy()\n",
    "dischargeSummary_notes_tokenized.loc[:, ['TEXT']] = dischargeSummary_notes_tokenized['TEXT'].map(\n",
    "    lambda x: [word.lower() for word in word_tokenize(x) \n",
    "        if word.lower() not in remove_cache # Not a stopword or punctuation\n",
    "            and not word.isdigit()          # Not a number\n",
    "            and not any([token.isdigit() for token in word]) # Does not contain a number\n",
    "            and not all([token in punctuation_cache for token in word]) # Is not only punctuation\n",
    "        ])\n",
    "\n",
    "print(dischargeSummary_notes_tokenized.head)\n",
    "print(dischargeSummary_notes_tokenized['TEXT'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3) Filtering for Longest Note per Admission\n",
    "The longest note in the admission is determined by the note text that contains the most tokens after processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total discharge summary notes w/ only longest:  52691\n",
      "<bound method NDFrame.head of        SUBJECT_ID   HADM_ID  \\\n",
      "17599       43126  124079.0   \n",
      "31434       42842  162017.0   \n",
      "51073       93321  115396.0   \n",
      "54248       51821  197028.0   \n",
      "1519        66807  166588.0   \n",
      "...           ...       ...   \n",
      "11081        3564  117638.0   \n",
      "12416        7995  190945.0   \n",
      "27470        6495  139808.0   \n",
      "36365         158  169433.0   \n",
      "20658       24855  156368.0   \n",
      "\n",
      "                                                    TEXT  NOTELENGTH  \n",
      "17599  [admission, date, discharge, date, date, birth...        4692  \n",
      "31434  [admission, date, discharge, date, date, birth...        4557  \n",
      "51073  [admission, date, discharge, date, date, birth...        4497  \n",
      "54248  [admission, date, discharge, date, date, birth...        4447  \n",
      "1519   [admission, date, discharge, date, date, birth...        4425  \n",
      "...                                                  ...         ...  \n",
      "11081  [admission, date, discharge, date, service, do...          50  \n",
      "12416  [admission, date, discharge, date, date, birth...          45  \n",
      "27470  [admission, date, discharge, date, date, birth...          39  \n",
      "36365  [admission, date, discharge, date, date, birth...          32  \n",
      "20658  [admission, date, discharge, date, service, hi...          29  \n",
      "\n",
      "[52691 rows x 4 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Only keep largest note per admission\n",
    "dischargeSummary_notes_tokenized.loc[:, ['NOTELENGTH']] = dischargeSummary_notes_tokenized['TEXT'].map(lambda x: len(x))\n",
    "dischargeSummary_admissions = dischargeSummary_notes_tokenized.sort_values('NOTELENGTH', ascending=False).drop_duplicates(['SUBJECT_ID', 'HADM_ID'])\n",
    "\n",
    "print(\"Total discharge summary notes w/ only longest: \", len(dischargeSummary_admissions))\n",
    "print(dischargeSummary_admissions.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5) Finding Heart Failure Admission with Discharge Summary Note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF Admissions w/ Notes #:  13746\n"
     ]
    }
   ],
   "source": [
    "# Find admissions w/ discharge summary notes\n",
    "hf_admissions_wNotes = HF_ADMISSIONS.merge(dischargeSummary_admissions, how='inner', on=['SUBJECT_ID', 'HADM_ID'])\n",
    "\n",
    "print(\"HF Admissions w/ Notes #: \", len(hf_admissions_wNotes))\n",
    "#print(hf_admissions_wNotes.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6) Replacing Word Tokens with Word Embedding Vector\n",
    "Word embeddings are taken from the publically available Word2Vec model, <a href=\"url\" target=\"https://bio.nlplab.org/\">bio.nlplab.org</a>, trained on PubMed abstracts and PubMed Central full text articles. \n",
    "\n",
    "If the word is not found in the model, the word vector is randomly initialized.\n",
    "\n",
    "Each word embedding is of shape (200,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained PubMed KeyedVectors through gensim\n",
    "pubmed_wv = KeyedVectors.load_word2vec_format(os.path.join(CURR_DIRNAME, r\"PubMed-and-PMC-w2v.bin\"), binary=True) \n",
    "hf_wv_admissions = hf_admissions_wNotes.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.1) Create weight and word to token index matrices for embedding layer in CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117152\n",
      "117153\n",
      "(117153, 200)\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables for weights and indices\n",
    "note_vocab = set()\n",
    "word2idx = {\"\":0}\n",
    "weights_matrix = [np.zeros((200), dtype=float)]\n",
    "idx = 1\n",
    "\n",
    "# Loop through all notes and word tokens in notes for admissions with notes\n",
    "for note in hf_wv_admissions['TEXT']:\n",
    "    for word in note:\n",
    "        # Add word to note vocabulary\n",
    "        note_vocab.add(word)\n",
    "        # Add word to index dictionary and weight matrix\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = idx\n",
    "            if word in pubmed_wv:\n",
    "                weights_matrix.append(pubmed_wv[word])\n",
    "            else:\n",
    "                weights_matrix.append(np.random.uniform(-1,1,(200)))\n",
    "            idx += 1\n",
    "\n",
    "# Convert weights list to numpy array\n",
    "weights_matrix = np.vstack(weights_matrix)\n",
    "\n",
    "print(len(note_vocab))\n",
    "print(len(word2idx))\n",
    "print(weights_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.2) Store word weights and word to index to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF Admissions w/ Notes WI #:  13746\n",
      "(1046,)\n",
      "[  1   2   3 ... 635 636 637]\n"
     ]
    }
   ],
   "source": [
    "# Add indexed word notes to dataframe\n",
    "hf_wv_admissions.loc[:, ['TEXT_INDICES']] = hf_wv_admissions['TEXT'].map(lambda x: [word2idx[word] for word in x])\n",
    "\n",
    "print(\"HF Admissions w/ Notes WI #: \", len(hf_wv_admissions))\n",
    "print(np.array(hf_wv_admissions['TEXT_INDICES'][0]).shape)\n",
    "print(np.array(hf_wv_admissions['TEXT_INDICES'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7) Positive Readmission Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF General Readmissions w/ Notes #:  3543\n",
      "HF 30-day Readmissions w/ Notes #:  962\n"
     ]
    }
   ],
   "source": [
    "# Find general readmissions w/ discharge summary notes\n",
    "HF_GEN_READMISSIONS_WNOTES = HF_GEN_READMISSIONS.merge(hf_wv_admissions, how='inner', on=['SUBJECT_ID', 'HADM_ID'])\n",
    "\n",
    "print(\"HF General Readmissions w/ Notes #: \", len(HF_GEN_READMISSIONS_WNOTES))\n",
    "#print(HF_GEN_READMISSIONS_WNOTES.head)\n",
    "\n",
    "# Find 30-day readmissions w/ discharge summary notes\n",
    "HF_30DAY_READMISSIONS_WNOTES = HF_30DAY_READMISSIONS.merge(hf_wv_admissions, how='inner', on=['SUBJECT_ID', 'HADM_ID'])\n",
    "\n",
    "print(\"HF 30-day Readmissions w/ Notes #: \", len(HF_30DAY_READMISSIONS_WNOTES))\n",
    "#print(HF_30DAY_READMISSIONS_WNOTES.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8) Negative Sampling\n",
    "Under-sampling is used to address the imbalance of positive to negative samples in the dataset. Negative samples are chosen in numbers matching the positive samples (general and 30-day readmissions) by selecting admissions without readmission and with discharge summary notes within the heart failure admission population. \n",
    "\n",
    "The goal of the model is to predict readmission within the heart failure population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF No General Readmissions w/ Notes #:  10203\n",
      "HF No 30-Day Readmissions w/ Notes #:  12784\n",
      "Sampled HF No General Readmissions w/ Notes #:  3543\n",
      "Sampled HF No 30-Day Readmissions w/ Notes #:  962\n"
     ]
    }
   ],
   "source": [
    "# Find heart failure admissions with discharge summary notes with no general readmissions\n",
    "positive_hf_readmissions = hf_wv_admissions.merge(HF_GEN_READMISSIONS_WNOTES, how='left', on=['SUBJECT_ID', 'HADM_ID'], indicator=True)\n",
    "negative_hf_readmissions = positive_hf_readmissions[positive_hf_readmissions['_merge'] == 'left_only'].copy()\n",
    "negative_hf_readmissions.rename(columns={\"TEXT_x\": \"TEXT\", \"NOTELENGTH_x\": \"NOTELENGTH\", \"TEXT_INDICES_x\":\"TEXT_INDICES\"}, inplace=True)\n",
    "\n",
    "print(\"HF No General Readmissions w/ Notes #: \", len(negative_hf_readmissions))\n",
    "\n",
    "# Find heart failure admissions with discharge summary notes with no 30-day readmissions\n",
    "positive_hf_30day_readmissions = hf_wv_admissions.merge(HF_30DAY_READMISSIONS_WNOTES, how='left', on=['SUBJECT_ID', 'HADM_ID'], indicator=True)\n",
    "negative_hf_30day_readmissions = positive_hf_30day_readmissions[positive_hf_30day_readmissions['_merge'] == 'left_only'].copy()\n",
    "negative_hf_30day_readmissions.rename(columns={\"TEXT_x\": \"TEXT\", \"NOTELENGTH_x\": \"NOTELENGTH\", \"TEXT_INDICES_x\":\"TEXT_INDICES\"}, inplace=True)\n",
    "\n",
    "print(\"HF No 30-Day Readmissions w/ Notes #: \", len(negative_hf_30day_readmissions))\n",
    "\n",
    "# Randomly sample from negative pool to match positive sample count\n",
    "readmission_gen_count = len(HF_GEN_READMISSIONS_WNOTES)\n",
    "no_readmission_gen_count = len(negative_hf_readmissions)\n",
    "negative_sample_list_gen = np.random.default_rng().choice(no_readmission_gen_count, (readmission_gen_count,), replace=False)\n",
    "HF_NO_GEN_READMISSIONS_WNOTES = negative_hf_readmissions.iloc[negative_sample_list_gen, :]\n",
    "print(\"Sampled HF No General Readmissions w/ Notes #: \", len(HF_NO_GEN_READMISSIONS_WNOTES))\n",
    "\n",
    "# readmission_30day_count = len(HF_30DAY_READMISSIONS_WNOTES)\n",
    "# no_readmission_30day_count = len(negative_hf_30day_readmissions)\n",
    "# negative_sample_list_30day = np.random.default_rng().choice(no_readmission_30day_count, (readmission_30day_count,), replace=False)\n",
    "# HF_NO_30DAY_READMISSIONS_WNOTES = negative_hf_30day_readmissions.iloc[negative_sample_list_30day, :]\n",
    "# print(\"Sampled HF No 30-Day Readmissions w/ Notes #: \", len(HF_NO_30DAY_READMISSIONS_WNOTES))\n",
    "\n",
    "readmission_30day_count = len(HF_30DAY_READMISSIONS_WNOTES)\n",
    "no_readmission_30day_count = len(negative_hf_readmissions)\n",
    "negative_sample_list_30day = np.random.default_rng().choice(no_readmission_30day_count, (readmission_30day_count,), replace=False)\n",
    "HF_NO_30DAY_READMISSIONS_WNOTES = negative_hf_readmissions.iloc[negative_sample_list_30day, :]\n",
    "print(\"Sampled HF No 30-Day Readmissions w/ Notes #: \", len(HF_NO_30DAY_READMISSIONS_WNOTES))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9) Save Processed Data to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final processed dataframes to file (pickle)\n",
    "HF_GEN_READMISSIONS_WNOTES[['TEXT_INDICES', 'NOTELENGTH', 'TEXT']].to_pickle(\"./positive_gen_readmissions.pkl.gz\")\n",
    "HF_30DAY_READMISSIONS_WNOTES[['TEXT_INDICES', 'NOTELENGTH', 'TEXT']].to_pickle(\"./positive_30day_readmissions.pkl.gz\")\n",
    "HF_NO_GEN_READMISSIONS_WNOTES[['TEXT_INDICES', 'NOTELENGTH', 'TEXT']].to_pickle(\"./negative_gen_readmissions.pkl.gz\")\n",
    "HF_NO_30DAY_READMISSIONS_WNOTES[['TEXT_INDICES', 'NOTELENGTH', 'TEXT']].to_pickle(\"./negative_30day_readmissions.pkl.gz\")\n",
    "# Save weight matrix (via numpy)\n",
    "with open('weights_matrix.npy', 'wb') as f:\n",
    "    np.save(f, weights_matrix)\n",
    "# Save word2idx (via pickle directly)\n",
    "with open('word2idx.pickle', 'wb') as f:\n",
    "    pickle.dump(word2idx, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed datasets\n",
    "HF_GEN_READMISSIONS_WNOTES = pd.read_pickle(\"./positive_gen_readmissions.pkl.gz\", compression=\"gzip\")\n",
    "HF_NO_GEN_READMISSIONS_WNOTES = pd.read_pickle(\"./negative_gen_readmissions.pkl.gz\", compression=\"gzip\")\n",
    "\n",
    "HF_30DAY_READMISSIONS_WNOTES = pd.read_pickle(\"./positive_30day_readmissions.pkl.gz\", compression=\"gzip\")\n",
    "HF_NO_30DAY_READMISSIONS_WNOTES = pd.read_pickle(\"./negative_30day_readmissions.pkl.gz\", compression=\"gzip\")\n",
    "\n",
    "# Load weight matrix (via numpy)\n",
    "with open('weights_matrix.npy', 'rb') as f:\n",
    "    weights_matrix = np.load(f)\n",
    "\n",
    "# Load word2idx (via pickle directly)\n",
    "with open('word2idx.pickle', 'rb') as f:\n",
    "    word2idx = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Convert Dataframes to Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1) Combine positive and negative samples into one dataframe per type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Readmission:  3543  +  3543  =  7086\n",
      "30-Day Readmission:  962  +  962  =  1924\n"
     ]
    }
   ],
   "source": [
    "readmission_gen_df = pd.concat([HF_GEN_READMISSIONS_WNOTES, HF_NO_GEN_READMISSIONS_WNOTES])\n",
    "readmission_30day_df = pd.concat([HF_30DAY_READMISSIONS_WNOTES, HF_NO_30DAY_READMISSIONS_WNOTES])\n",
    "\n",
    "print(\"General Readmission: \", len(HF_GEN_READMISSIONS_WNOTES), \" + \", len(HF_NO_GEN_READMISSIONS_WNOTES), \" = \", len(readmission_gen_df))\n",
    "print(\"30-Day Readmission: \", len(HF_30DAY_READMISSIONS_WNOTES), \" + \", len(HF_NO_30DAY_READMISSIONS_WNOTES), \" = \", len(readmission_30day_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2) Find max note lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Note Length - General Readmissions:  3987\n",
      "Max Note Length - 30-Day Readmissions:  3750\n"
     ]
    }
   ],
   "source": [
    "max_words_gen_readmit = int(readmission_gen_df['NOTELENGTH'].max())\n",
    "max_words_30day_readmit = int(readmission_30day_df['NOTELENGTH'].max())\n",
    "\n",
    "print(\"Max Note Length - General Readmissions: \", max_words_gen_readmit)\n",
    "print(\"Max Note Length - 30-Day Readmissions: \", max_words_30day_readmit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3) Pad note vectors to max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7086, 3987)\n",
      "(1924, 3750)\n"
     ]
    }
   ],
   "source": [
    "# Text Embedding Vectors\n",
    "padded_note_wv_gen_readmit = pad_sequences(readmission_gen_df['TEXT_INDICES'], maxlen=max_words_gen_readmit, padding=\"post\", value=0, dtype=int)\n",
    "padded_note_wv_30day_readmit = pad_sequences(readmission_30day_df['TEXT_INDICES'], maxlen=max_words_30day_readmit, padding=\"post\", value=0, dtype=int)\n",
    "\n",
    "print(padded_note_wv_gen_readmit.shape)\n",
    "print(padded_note_wv_30day_readmit.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4) Convert dataframes to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7086, 3987])\n",
      "torch.Size([1924, 3750])\n"
     ]
    }
   ],
   "source": [
    "# Text Embedding Vectors\n",
    "readmission_gen_tensor = torch.tensor(padded_note_wv_gen_readmit, dtype=int)\n",
    "readmission_30day_tensor = torch.tensor(padded_note_wv_30day_readmit, dtype=int)\n",
    "\n",
    "print(readmission_gen_tensor.shape)\n",
    "print(readmission_30day_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7086,)\n",
      "(1924,)\n"
     ]
    }
   ],
   "source": [
    "# Text Token Vectors\n",
    "readmission_gen_tensor_tokens = np.array(readmission_gen_df['TEXT'])\n",
    "readmission_30day_tensor_tokens = np.array(readmission_30day_df['TEXT'])\n",
    "\n",
    "print(readmission_gen_tensor_tokens.shape)\n",
    "print(readmission_30day_tensor_tokens.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5) Create labels for positive and negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7086])\n",
      "torch.Size([1924])\n"
     ]
    }
   ],
   "source": [
    "readmission_gen_labels = torch.cat(\n",
    "    (\n",
    "        torch.ones((len(HF_GEN_READMISSIONS_WNOTES),)), \n",
    "        torch.zeros((len(HF_NO_GEN_READMISSIONS_WNOTES),))\n",
    "    )\n",
    ")\n",
    "readmission_30day_labels = torch.cat(\n",
    "    (\n",
    "        torch.ones((len(HF_30DAY_READMISSIONS_WNOTES),)), \n",
    "        torch.zeros((len(HF_NO_30DAY_READMISSIONS_WNOTES),))\n",
    "    )\n",
    ")\n",
    "\n",
    "print(readmission_gen_labels.shape)\n",
    "print(readmission_30day_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save([readmission_gen_tensor, readmission_gen_labels, readmission_gen_tensor_tokens], 'readmission_gen_tensors.pt')\n",
    "torch.save([readmission_30day_tensor, readmission_30day_labels, readmission_30day_tensor_tokens], 'readmission_30day_tensors.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "readmission_gen_tensor, readmission_gen_labels, readmission_gen_tensor_tokens = torch.load('readmission_gen_tensors.pt')\n",
    "readmission_30day_tensor, readmission_30day_labels, readmission_30day_tensor_tokens = torch.load('readmission_30day_tensors.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weight matrix (via numpy)\n",
    "with open('weights_matrix.npy', 'rb') as f:\n",
    "    weights_matrix = np.load(f)\n",
    "\n",
    "# Load word2idx (via pickle directly)\n",
    "with open('word2idx.pickle', 'rb') as f:\n",
    "    word2idx = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, wv, labels, tokens):\n",
    "        \"\"\"\n",
    "        Store `seqs`. to `self.x` and `hfs` to `self.y`.\n",
    "        \"\"\"\n",
    "        self.x = wv\n",
    "        self.y = labels\n",
    "        self.tokens = tokens\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the number of samples (i.e. admissions).\n",
    "        \"\"\"\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Generates one sample of data.\n",
    "        \"\"\"\n",
    "        return self.x[index], self.y[index], len(self.tokens[index]), index\n",
    "    \n",
    "    def getToken(self, index):\n",
    "        \"\"\"\n",
    "        Generates one sample of tokens\n",
    "        \"\"\"\n",
    "        return self.tokens[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets for the general and 30-day readmissions\n",
    "readmission_gen_dataset = CustomDataset(readmission_gen_tensor, readmission_gen_labels, readmission_gen_tensor_tokens)\n",
    "readmission_30day_dataset = CustomDataset(readmission_30day_tensor, readmission_30day_labels, readmission_30day_tensor_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) Create Test and Training Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_random_split(dataset, print_details = True):\n",
    "    # Split is 90/10 for training/testing\n",
    "    split_len = int(len(dataset)*0.9)\n",
    "    split_lengths = [split_len, len(dataset) - split_len]\n",
    "\n",
    "    # Create general readmission training and testing sets\n",
    "    train_dataset, val_dataset = random_split(dataset, split_lengths)\n",
    "\n",
    "    if print_details:\n",
    "        print(\"Length of train dataset:\", len(train_dataset))\n",
    "        print(\"Length of val dataset:\", len(val_dataset))\n",
    "\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 6377\n",
      "Length of val dataset: 709\n",
      "Length of train dataset: 1731\n",
      "Length of val dataset: 193\n"
     ]
    }
   ],
   "source": [
    "train_dataset_gen, val_dataset_gen = dataset_random_split(readmission_gen_dataset)\n",
    "train_dataset_30day, val_dataset_30day = dataset_random_split(readmission_30day_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4) Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define load data function for dataloader creation\n",
    "def load_data(train_dataset, val_dataset=None, batch_size = 32, train_sampler=None, val_sampler=None, collate_fn = None):\n",
    "    '''\n",
    "    Returns the data loader for train and validation dataset. \n",
    "    Set batchsize default to 32. \n",
    "    Set `shuffle=True` only for train dataloader.\n",
    "    \n",
    "    Arguments:\n",
    "        train dataset: train dataset of type `CustomDataset`\n",
    "        val dataset: validation dataset of type `CustomDataset`\n",
    "        collate_fn: collate function\n",
    "        batch_size: size of batches, default to 32\n",
    "        \n",
    "    Outputs:\n",
    "        train_loader, val_loader: train and validation dataloaders\n",
    "    '''\n",
    "    train_loader = None\n",
    "    val_loader = None\n",
    "    if train_sampler is None or val_sampler is None:\n",
    "        train_loader = DataLoader(train_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True,\n",
    "                                collate_fn=collate_fn)\n",
    "        \n",
    "        val_loader = DataLoader(val_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                collate_fn=collate_fn)\n",
    "    else:\n",
    "        train_loader = DataLoader(train_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                sampler=train_sampler)\n",
    "        \n",
    "        val_loader = DataLoader(train_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                sampler=val_sampler)\n",
    "    \n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for datasets\n",
    "train_loader_gen, val_loader_gen = load_data(train_dataset_gen, val_dataset_gen)\n",
    "train_loader_30day, val_loader_30day = load_data(train_dataset_30day, val_dataset_30day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Build CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoteCNN(nn.Module):\n",
    "    def __init__(self, weights_matrix, filter_count=100, dropout_p=0.5, filter_layers=[1, 1, 1]):\n",
    "        super(NoteCNN, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.tensor(weights_matrix, dtype=torch.float), padding_idx=0)\n",
    "        \n",
    "        self.conv1_list = nn.ModuleList([nn.Conv1d(200, filter_count, kernel_size = 1, stride = 1) for i in range(filter_layers[0])])\n",
    "        self.conv2_list = nn.ModuleList([nn.Conv1d(200, filter_count, kernel_size = 2, stride = 1) for i in range(filter_layers[1])])\n",
    "        self.conv3_list = nn.ModuleList([nn.Conv1d(200, filter_count, kernel_size = 3, stride = 1) for i in range(filter_layers[2])])\n",
    "        \n",
    "        self.fc = nn.Linear(filter_count * np.sum(filter_layers), filter_count * 2)\n",
    "        self.fc_2 = nn.Linear(filter_count * 2, filter_count)\n",
    "        self.fc_3 = nn.Linear(filter_count, 2)\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Translate word idx to word embeddings\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # Change order of dimensions to make embedding dim before length\n",
    "        x = torch.permute(x, (0, 2, 1))\n",
    "        \n",
    "        # Use convolution layers to create filters for each filter size\n",
    "        # Input: x_n.shape = (N, C_in, L) = (batch, embedding_size, max_note_length)\n",
    "        x_1_list = [F.relu(conv1(x)) for conv1 in self.conv1_list]\n",
    "        x_2_list = [F.relu(conv2(x)) for conv2 in self.conv2_list]\n",
    "        x_3_list = [F.relu(conv3(x)) for conv3 in self.conv3_list]\n",
    "        \n",
    "        # Find maximum value across filters (max pool over time) using L_out and remove extra dimension\n",
    "        # Input: x_n.shape = (N, C_out, L_out) = (batch, filter_count, conv_output)\n",
    "        x_max_1_list = [torch.squeeze(F.max_pool1d(x_1, kernel_size=x_1.shape[2]), dim=2) for x_1 in x_1_list]\n",
    "        x_max_2_list = [torch.squeeze(F.max_pool1d(x_2, kernel_size=x_2.shape[2]), dim=2) for x_2 in x_2_list]\n",
    "        x_max_3_list = [torch.squeeze(F.max_pool1d(x_3, kernel_size=x_3.shape[2]), dim=2) for x_3 in x_3_list]\n",
    "        \n",
    "        # Combine filters together\n",
    "        x_layers_1 = torch.cat(x_max_1_list, dim=1)\n",
    "        x_layers_2 = torch.cat(x_max_2_list, dim=1)\n",
    "        x_layers_3 = torch.cat(x_max_3_list, dim=1)\n",
    "        x_layers = torch.cat([x_layers_1, x_layers_2, x_layers_3], dim=1)\n",
    "        \n",
    "        # Fully connected layer to find most prediction\n",
    "        pred = F.relu(self.fc(self.dropout(x_layers)))\n",
    "        pred = F.relu(self.fc_2(pred))\n",
    "        pred = F.log_softmax(self.fc_3(pred), dim=1)\n",
    "        #pred = self.fc_3(pred) # For use with BCE with logits\n",
    "        #pred = torch.sigmoid(self.fc(self.dropout(x_layers))) # For use with BCE\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoteCNN size in GB: 0.096488804\n",
      "NoteCNN parameters:  691601\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = NoteCNN(weights_matrix)\n",
    "\n",
    "model_size = sum([param.nelement() * param.element_size() for param in model.parameters()]) / 1e9\n",
    "print(\"NoteCNN size in GB:\", model_size)\n",
    "model_parameters_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"NoteCNN parameters: \", model_parameters_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1) Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default learning rate\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Set default loss and optimization functions\n",
    "#CRITERION = nn.CrossEntropyLoss()\n",
    "#CRITERION = nn.BCELoss()\n",
    "CRITERION = nn.BCEWithLogitsLoss()\n",
    "OPTIMIZER = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2) Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "def train_model(model, dataloader, n_epoch=N_EPOCHS, optimizer=OPTIMIZER, criterion=CRITERION, device=None, val_dataloader = None):\n",
    "    \"\"\"\n",
    "    :param model: A CNN model\n",
    "    :param dataloader: the DataLoader of the training data\n",
    "    :param n_epoch: number of epochs to train\n",
    "    :return:\n",
    "        model: trained model\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device('cuda')\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "    \n",
    "    model.train() # prep model for training\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        curr_epoch_loss = []\n",
    "        curr_training_acc = []\n",
    "        epoch_start_time = time.time()\n",
    "        for data, target, mask, _ in dataloader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device).long()\n",
    "            mask = mask.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            prediction = torch.squeeze(output, dim=1)\n",
    "            \n",
    "            loss = criterion(prediction, target) # For non-BCE Loss\n",
    "            #loss = criterion(prediction, target.float()) # For BCE Loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            curr_epoch_loss.append(loss.cpu().item())\n",
    "            _, prediction = torch.max(prediction, 1) # For non-BCE Loss\n",
    "            curr_training_acc.append(accuracy_score(prediction.cpu(), target.cpu())) # For non-BCE Loss\n",
    "            #curr_training_acc.append(accuracy_score((torch.sigmoid(prediction.cpu()) >= 0.5).long(), target.cpu())) # For BCE Loss\n",
    "\n",
    "        acc = None\n",
    "        if val_dataloader is not None:\n",
    "            (prec, recall, f1, acc), _ = evaluation_metrics(model, val_dataloader, print_out=False, device=device)\n",
    "\n",
    "        if acc is None:\n",
    "            print(f\"Epoch {epoch+1}: curr_epoch_loss={np.mean(curr_epoch_loss)}, running time = {time.time() - epoch_start_time} seconds, training accuracy = {np.mean(curr_training_acc)}\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1}: curr_epoch_loss={np.mean(curr_epoch_loss)}, running time = {time.time() - epoch_start_time} seconds, training accuracy = {np.mean(curr_training_acc)}, validation accuracy = {acc}\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3) Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader, device = None):\n",
    "    \"\"\"\n",
    "    Evaluate the model using data in data loader\n",
    "    :return:\n",
    "        Y_pred: prediction of model on the dataloder.\n",
    "            Should be an 2D numpy float array where the second dimension has length 2.\n",
    "        Y_test: truth labels. Should be an numpy array of ints\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device('cuda')\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "        print(\"device reset to : \", device)\n",
    "    \n",
    "    model.eval()\n",
    "    Y_pred = []\n",
    "    Y_test = []\n",
    "    Y_data = []\n",
    "    Y_data_labels = []\n",
    "    Y_tokens = []\n",
    "    for data, target, mask, index in dataloader:\n",
    "        data = data.to(device)\n",
    "        target = target.cpu().long()\n",
    "        mask = mask.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "        _, prediction = torch.max(output, 1)\n",
    "        prediction = prediction.cpu()\n",
    "        #prediction = (torch.sigmoid(torch.squeeze(output, dim=1).cpu()) >= 0.5).long()\n",
    "        \n",
    "        data = data.cpu()\n",
    "        Y_pred.append(prediction)\n",
    "        Y_test.append(target)\n",
    "\n",
    "        Y_data.append(data[(prediction == target)])\n",
    "        Y_data_labels.append(prediction[(prediction == target)])\n",
    "        Y_tokens.append(index[(prediction == target)])\n",
    "        \n",
    "    Y_pred = np.concatenate(Y_pred, axis=0)\n",
    "    Y_test = np.concatenate(Y_test, axis=0)\n",
    "\n",
    "    return (Y_pred, Y_test), (Y_data, Y_data_labels, Y_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4) Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metrics(model, validation_dataloader, print_out = True, device = None, dataset = None):\n",
    "    (y_pred, y_true), (y_data, y_data_labels, y_tokens) = eval_model(model, validation_dataloader, device = device)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    prec = precision_score(y_pred, y_true, zero_division = 0)\n",
    "    recall = recall_score(y_pred, y_true, zero_division = 0)\n",
    "    f1 = f1_score(y_pred, y_true, zero_division = 0)\n",
    "    acc = accuracy_score(y_pred, y_true)\n",
    "\n",
    "    # Print the evaluation metrics\n",
    "    if print_out: \n",
    "        print((\"Validation Precision: \" + str(prec)))\n",
    "        print((\"Validation Recall: \" + str(recall)))\n",
    "        print((\"Validation F1: \" + str(f1)))\n",
    "        print((\"Validation Accuracy: \" + str(acc)))\n",
    "\n",
    "    # Transform samples into tensors\n",
    "    tokens = None\n",
    "    sample_labels = None\n",
    "    if dataset is not None:\n",
    "        sample_labels = torch.hstack(y_data_labels)\n",
    "        tokens_indicis = torch.hstack(y_tokens)\n",
    "        tokens = np.array([dataset.getToken(idx) for idx in tokens_indicis], dtype=object)\n",
    "\n",
    "    return (prec, recall, f1, acc), (tokens, sample_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3) Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "KFOLD_SPLITS = 10\n",
    "\n",
    "def train_validate_CNN(dataset, weights_matrix, kfolds = KFOLD_SPLITS, epochs = 11, n_features = 50, dropout_p = 0.3, learning_rate = 0.0003, filter_layers=[5, 5, 5], batch_size=128):\n",
    "    # Record start time\n",
    "    _START_RUNTIME = time.time()\n",
    "\n",
    "    # Set device for training model\n",
    "    device = torch.device('cpu')\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    # Train the model with k-fold validation\n",
    "    tokens_list = []\n",
    "    sample_labels_list = []\n",
    "\n",
    "    #kf = KFold(n_splits=kfolds, shuffle=True)\n",
    "    kf = StratifiedKFold(n_splits=kfolds, shuffle=True)\n",
    "    #kf = ShuffleSplit(n_splits=kfolds, test_size=0.1, train_size=0.9)\n",
    "\n",
    "    results = []\n",
    "    for fold_idx, (train_index, val_index) in enumerate(kf.split(dataset.x, dataset.y)):\n",
    "        print(\"---------------------------------------------------------------------------\")\n",
    "        print(\"Current Fold: \", fold_idx+1)\n",
    "        print(\"---------------------------------------------------------------------------\")\n",
    "\n",
    "        # Initialize CNN model \n",
    "        model = NoteCNN(weights_matrix, n_features, dropout_p, filter_layers=filter_layers)\n",
    "        model = model.to(device)\n",
    "\n",
    "        # Define loss and optimization functions\n",
    "        #criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "        criterion = nn.NLLLoss().to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Train CNN model\n",
    "        train_sampler = SubsetRandomSampler(train_index)\n",
    "        val_sampler = SubsetRandomSampler(val_index)\n",
    "        train_loader, val_loader = load_data(dataset, train_sampler=train_sampler, val_sampler=val_sampler, batch_size=batch_size)\n",
    "        trained_model = train_model(model, train_loader, n_epoch=epochs, optimizer=optimizer, criterion=criterion, device=device, val_dataloader=val_loader)\n",
    "\n",
    "        # Test CNN model\n",
    "        (prec, recall, f1, acc), (tokens, sample_labels) = evaluation_metrics(trained_model, val_loader, device=device, dataset=dataset)\n",
    "\n",
    "        # Save off tokens and sample labels for interpretation later\n",
    "        tokens_list.append(tokens)\n",
    "        sample_labels_list.append(sample_labels)\n",
    "\n",
    "        # Save the evaluation metrics for averaging across all folds\n",
    "        results.append([prec, recall, f1, acc])\n",
    "\n",
    "        # Clear memory for GPU\n",
    "        del model, criterion, optimizer, train_sampler, val_sampler, train_loader, val_loader, trained_model\n",
    "        gc.collect()\n",
    "        if device == torch.device('cuda'):\n",
    "            mem_alloc = torch.cuda.memory_allocated() / 1024**2\n",
    "            mem_cache = torch.cuda.memory_reserved() / 1024**2\n",
    "            torch.cuda.empty_cache()\n",
    "            print(f\"Empty Cache: Allocated - {torch.cuda.memory_allocated() / 1024**2}/{mem_alloc} Cached - {torch.cuda.memory_reserved() / 1024**2}/{mem_cache}\")\n",
    "\n",
    "    # Calculate average evaluation metrics\n",
    "    avg_results = np.sum(results, axis=0)/float(KFOLD_SPLITS)\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "    print(f\"Stratified k-fold: Model with {n_features} features, learning rate {learning_rate}, dropout_p {dropout_p}, epochs {epochs}, layers {filter_layers}\")\n",
    "    print((\"Avg Validation Precision: \" + str(avg_results[0])))\n",
    "    print((\"Avg Validation Recall: \" + str(avg_results[1])))\n",
    "    print((\"Avg Validation F1: \" + str(avg_results[2])))\n",
    "    print((\"Avg Validation Accuracy: \" + str(avg_results[3])))\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "    # Get total run time\n",
    "    print(\"Total running time = {:.2f} seconds\".format(time.time() - _START_RUNTIME))\n",
    "\n",
    "    return tokens_list, sample_labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Current Fold:  1\n",
      "---------------------------------------------------------------------------\n",
      "Epoch 1: curr_epoch_loss=0.6914752161502838, running time = 21.21837615966797 seconds, training accuracy = 0.5240550595238095, validation accuracy = 0.5698166431593794\n",
      "Epoch 2: curr_epoch_loss=0.665043227672577, running time = 42.754870891571045 seconds, training accuracy = 0.6259404761904762, validation accuracy = 0.6276445698166432\n",
      "Epoch 3: curr_epoch_loss=0.6171566724777222, running time = 34.68338084220886 seconds, training accuracy = 0.6672544642857143, validation accuracy = 0.6234132581100141\n",
      "Epoch 4: curr_epoch_loss=0.5717970931529999, running time = 28.910229921340942 seconds, training accuracy = 0.7116636904761904, validation accuracy = 0.607898448519041\n",
      "Epoch 5: curr_epoch_loss=0.5148456168174743, running time = 28.846740245819092 seconds, training accuracy = 0.7525282738095238, validation accuracy = 0.6262341325811002\n",
      "Epoch 6: curr_epoch_loss=0.4182608646154404, running time = 33.676681995391846 seconds, training accuracy = 0.8343988095238095, validation accuracy = 0.6304654442877292\n",
      "Epoch 7: curr_epoch_loss=0.30196051895618437, running time = 53.108049392700195 seconds, training accuracy = 0.9043452380952381, validation accuracy = 0.6177715091678421\n",
      "Epoch 8: curr_epoch_loss=0.1824554005265236, running time = 52.410305976867676 seconds, training accuracy = 0.9625877976190477, validation accuracy = 0.616361071932299\n",
      "Epoch 9: curr_epoch_loss=0.08901738695800304, running time = 31.0806667804718 seconds, training accuracy = 0.99375, validation accuracy = 0.613540197461213\n",
      "Epoch 10: curr_epoch_loss=0.042026494331657886, running time = 20.963576555252075 seconds, training accuracy = 0.99890625, validation accuracy = 0.6177715091678421\n",
      "Epoch 11: curr_epoch_loss=0.02263387691229582, running time = 20.60672354698181 seconds, training accuracy = 0.99953125, validation accuracy = 0.616361071932299\n",
      "Validation Precision: 0.7605633802816901\n",
      "Validation Recall: 0.5908096280087527\n",
      "Validation F1: 0.665024630541872\n",
      "Validation Accuracy: 0.616361071932299\n",
      "Empty Cache: Allocated - 0.0/0.0 Cached - 0.0/4318.0\n",
      "---------------------------------------------------------------------------\n",
      "Current Fold:  2\n",
      "---------------------------------------------------------------------------\n",
      "Epoch 1: curr_epoch_loss=0.6902882122993469, running time = 20.83623743057251 seconds, training accuracy = 0.5326145833333333, validation accuracy = 0.5133991537376587\n",
      "Epoch 2: curr_epoch_loss=0.661814432144165, running time = 20.88575792312622 seconds, training accuracy = 0.6184211309523809, validation accuracy = 0.6064880112834978\n",
      "Epoch 3: curr_epoch_loss=0.6171377825737, running time = 20.868102550506592 seconds, training accuracy = 0.6633675595238095, validation accuracy = 0.6262341325811002\n",
      "Epoch 4: curr_epoch_loss=0.5757898592948913, running time = 21.121834993362427 seconds, training accuracy = 0.7026011904761904, validation accuracy = 0.6318758815232722\n",
      "Epoch 5: curr_epoch_loss=0.5084601670503617, running time = 21.3285653591156 seconds, training accuracy = 0.7641592261904762, validation accuracy = 0.6403385049365303\n",
      "Epoch 6: curr_epoch_loss=0.4135863137245178, running time = 21.00320339202881 seconds, training accuracy = 0.8338958333333334, validation accuracy = 0.6304654442877292\n",
      "Epoch 7: curr_epoch_loss=0.2992816424369812, running time = 20.77333164215088 seconds, training accuracy = 0.8993407738095237, validation accuracy = 0.6417489421720733\n",
      "Epoch 8: curr_epoch_loss=0.16974994122982026, running time = 20.72597908973694 seconds, training accuracy = 0.9702291666666666, validation accuracy = 0.6332863187588152\n",
      "Epoch 9: curr_epoch_loss=0.08308607809245587, running time = 20.726821660995483 seconds, training accuracy = 0.99375, validation accuracy = 0.6304654442877292\n",
      "Epoch 10: curr_epoch_loss=0.036513019651174546, running time = 20.69192099571228 seconds, training accuracy = 0.9996875, validation accuracy = 0.6248236953455572\n",
      "Epoch 11: curr_epoch_loss=0.018169457819312812, running time = 20.722678899765015 seconds, training accuracy = 1.0, validation accuracy = 0.6248236953455572\n",
      "Validation Precision: 0.5859154929577465\n",
      "Validation Recall: 0.636085626911315\n",
      "Validation F1: 0.6099706744868035\n",
      "Validation Accuracy: 0.6248236953455572\n",
      "Empty Cache: Allocated - 0.0/0.0 Cached - 0.0/4318.0\n",
      "---------------------------------------------------------------------------\n",
      "Current Fold:  3\n",
      "---------------------------------------------------------------------------\n",
      "Epoch 1: curr_epoch_loss=0.6905030333995819, running time = 20.742488145828247 seconds, training accuracy = 0.5306324404761905, validation accuracy = 0.5952045133991537\n",
      "Epoch 2: curr_epoch_loss=0.6643108260631562, running time = 20.67280673980713 seconds, training accuracy = 0.6203839285714285, validation accuracy = 0.5543018335684062\n",
      "Epoch 3: curr_epoch_loss=0.622208286523819, running time = 20.992186546325684 seconds, training accuracy = 0.6573764880952381, validation accuracy = 0.6346967559943583\n",
      "Epoch 4: curr_epoch_loss=0.5815208518505096, running time = 20.89444351196289 seconds, training accuracy = 0.7039732142857144, validation accuracy = 0.6417489421720733\n",
      "Epoch 5: curr_epoch_loss=0.5128772801160812, running time = 20.877537727355957 seconds, training accuracy = 0.7607604166666667, validation accuracy = 0.6389280677009873\n",
      "Epoch 6: curr_epoch_loss=0.41938740372657773, running time = 21.029222011566162 seconds, training accuracy = 0.8263467261904762, validation accuracy = 0.6431593794076164\n",
      "Epoch 7: curr_epoch_loss=0.2962812852859497, running time = 20.745174646377563 seconds, training accuracy = 0.9068452380952381, validation accuracy = 0.6643159379407616\n",
      "Epoch 8: curr_epoch_loss=0.17124641463160514, running time = 20.58465266227722 seconds, training accuracy = 0.9687693452380952, validation accuracy = 0.6657263751763046\n",
      "Epoch 9: curr_epoch_loss=0.08254769884049892, running time = 20.62929630279541 seconds, training accuracy = 0.9934032738095238, validation accuracy = 0.6727785613540197\n",
      "Epoch 10: curr_epoch_loss=0.03697881814092398, running time = 20.617441177368164 seconds, training accuracy = 0.99921875, validation accuracy = 0.6657263751763046\n",
      "Epoch 11: curr_epoch_loss=0.01810408992692828, running time = 20.7143452167511 seconds, training accuracy = 1.0, validation accuracy = 0.6699576868829337\n",
      "Validation Precision: 0.6169014084507042\n",
      "Validation Recall: 0.6908517350157729\n",
      "Validation F1: 0.6517857142857143\n",
      "Validation Accuracy: 0.6699576868829337\n",
      "Empty Cache: Allocated - 0.0/0.0 Cached - 0.0/4318.0\n",
      "---------------------------------------------------------------------------\n",
      "Current Fold:  4\n",
      "---------------------------------------------------------------------------\n",
      "Epoch 1: curr_epoch_loss=0.6922453248500824, running time = 20.82827091217041 seconds, training accuracy = 0.5173467261904762, validation accuracy = 0.4992947813822285\n",
      "Epoch 2: curr_epoch_loss=0.6794719719886779, running time = 20.679516792297363 seconds, training accuracy = 0.5628839285714285, validation accuracy = 0.6036671368124118\n",
      "Epoch 3: curr_epoch_loss=0.6407662892341613, running time = 20.610339879989624 seconds, training accuracy = 0.6489880952380952, validation accuracy = 0.6290550070521862\n",
      "Epoch 4: curr_epoch_loss=0.6068239116668701, running time = 21.022323846817017 seconds, training accuracy = 0.6733184523809524, validation accuracy = 0.6671368124118476\n",
      "Epoch 5: curr_epoch_loss=0.5594430792331696, running time = 20.733220100402832 seconds, training accuracy = 0.7231235119047619, validation accuracy = 0.6741889985895627\n",
      "Epoch 6: curr_epoch_loss=0.49210824370384215, running time = 20.630201816558838 seconds, training accuracy = 0.7827529761904762, validation accuracy = 0.6643159379407616\n",
      "Epoch 7: curr_epoch_loss=0.3976527065038681, running time = 20.65394616127014 seconds, training accuracy = 0.8499360119047619, validation accuracy = 0.68688293370945\n",
      "Epoch 8: curr_epoch_loss=0.28101479053497314, running time = 20.59412121772766 seconds, training accuracy = 0.9159077380952381, validation accuracy = 0.6586741889985895\n",
      "Epoch 9: curr_epoch_loss=0.16909022986888886, running time = 20.744723558425903 seconds, training accuracy = 0.9714255952380952, validation accuracy = 0.6488011283497884\n",
      "Epoch 10: curr_epoch_loss=0.08732852905988693, running time = 20.771140575408936 seconds, training accuracy = 0.9943065476190476, validation accuracy = 0.6629055007052186\n",
      "Epoch 11: curr_epoch_loss=0.0418173398822546, running time = 20.77079176902771 seconds, training accuracy = 0.99921875, validation accuracy = 0.6741889985895627\n",
      "Validation Precision: 0.635593220338983\n",
      "Validation Recall: 0.6880733944954128\n",
      "Validation F1: 0.6607929515418501\n",
      "Validation Accuracy: 0.6741889985895627\n",
      "Empty Cache: Allocated - 0.0/0.0 Cached - 0.0/4318.0\n",
      "---------------------------------------------------------------------------\n",
      "Current Fold:  5\n",
      "---------------------------------------------------------------------------\n",
      "Epoch 1: curr_epoch_loss=0.6913282263278961, running time = 20.833806037902832 seconds, training accuracy = 0.5249494047619048, validation accuracy = 0.6050775740479548\n",
      "Epoch 2: curr_epoch_loss=0.658879212141037, running time = 20.738832235336304 seconds, training accuracy = 0.6169270833333333, validation accuracy = 0.6318758815232722\n",
      "Epoch 3: curr_epoch_loss=0.6198429131507873, running time = 20.673822164535522 seconds, training accuracy = 0.6582157738095238, validation accuracy = 0.6643159379407616\n",
      "Epoch 4: curr_epoch_loss=0.5686704993247986, running time = 20.72849941253662 seconds, training accuracy = 0.711751488095238, validation accuracy = 0.6332863187588152\n",
      "Epoch 5: curr_epoch_loss=0.5125838893651963, running time = 21.118560314178467 seconds, training accuracy = 0.7604285714285715, validation accuracy = 0.6600846262341326\n",
      "Epoch 6: curr_epoch_loss=0.4172085064649582, running time = 21.13084125518799 seconds, training accuracy = 0.8285491071428571, validation accuracy = 0.6671368124118476\n",
      "Epoch 7: curr_epoch_loss=0.3065134111046791, running time = 20.638399362564087 seconds, training accuracy = 0.898983630952381, validation accuracy = 0.6614950634696756\n",
      "Epoch 8: curr_epoch_loss=0.17645429879426955, running time = 20.604894399642944 seconds, training accuracy = 0.9715818452380952, validation accuracy = 0.6629055007052186\n",
      "Epoch 9: curr_epoch_loss=0.08942812964320183, running time = 20.746707677841187 seconds, training accuracy = 0.9943407738095238, validation accuracy = 0.6544428772919605\n",
      "Epoch 10: curr_epoch_loss=0.04356905072927475, running time = 20.60834789276123 seconds, training accuracy = 0.999375, validation accuracy = 0.6755994358251057\n",
      "Epoch 11: curr_epoch_loss=0.02166184991598129, running time = 20.269708395004272 seconds, training accuracy = 1.0, validation accuracy = 0.6770098730606487\n",
      "Validation Precision: 0.6779661016949152\n",
      "Validation Recall: 0.676056338028169\n",
      "Validation F1: 0.6770098730606489\n",
      "Validation Accuracy: 0.6770098730606487\n",
      "Empty Cache: Allocated - 0.0/0.0 Cached - 0.0/4318.0\n",
      "---------------------------------------------------------------------------\n",
      "Current Fold:  6\n",
      "---------------------------------------------------------------------------\n",
      "Epoch 1: curr_epoch_loss=0.6896553540229797, running time = 20.226561784744263 seconds, training accuracy = 0.5303199404761905, validation accuracy = 0.5768688293370945\n",
      "Epoch 2: curr_epoch_loss=0.6597647631168365, running time = 20.036540746688843 seconds, training accuracy = 0.6213020833333334, validation accuracy = 0.6332863187588152\n",
      "Epoch 3: curr_epoch_loss=0.6230930876731873, running time = 20.03485083580017 seconds, training accuracy = 0.654485119047619, validation accuracy = 0.6177715091678421\n",
      "Epoch 4: curr_epoch_loss=0.5855551517009735, running time = 20.138335466384888 seconds, training accuracy = 0.6892321428571428, validation accuracy = 0.6459802538787024\n",
      "Epoch 5: curr_epoch_loss=0.5186663633584976, running time = 19.97712230682373 seconds, training accuracy = 0.7619761904761905, validation accuracy = 0.6685472496473907\n",
      "Epoch 6: curr_epoch_loss=0.4317480993270874, running time = 19.848318576812744 seconds, training accuracy = 0.8231532738095239, validation accuracy = 0.6586741889985895\n",
      "Epoch 7: curr_epoch_loss=0.30571423918008805, running time = 20.096905946731567 seconds, training accuracy = 0.9057172619047619, validation accuracy = 0.6657263751763046\n",
      "Epoch 8: curr_epoch_loss=0.18415705740451813, running time = 20.811145067214966 seconds, training accuracy = 0.9630223214285714, validation accuracy = 0.6417489421720733\n",
      "Epoch 9: curr_epoch_loss=0.09198294311761857, running time = 20.71641445159912 seconds, training accuracy = 0.991875, validation accuracy = 0.6671368124118476\n",
      "Epoch 10: curr_epoch_loss=0.040526762716472146, running time = 20.644129753112793 seconds, training accuracy = 0.9990282738095237, validation accuracy = 0.6403385049365303\n",
      "Epoch 11: curr_epoch_loss=0.02010986492037773, running time = 20.676666259765625 seconds, training accuracy = 1.0, validation accuracy = 0.6600846262341326\n",
      "Validation Precision: 0.6497175141242938\n",
      "Validation Recall: 0.6628242074927954\n",
      "Validation F1: 0.6562054208273894\n",
      "Validation Accuracy: 0.6600846262341326\n",
      "Empty Cache: Allocated - 0.0/0.0 Cached - 0.0/4318.0\n",
      "---------------------------------------------------------------------------\n",
      "Current Fold:  7\n",
      "---------------------------------------------------------------------------\n",
      "Epoch 1: curr_epoch_loss=0.6908606350421905, running time = 20.83866572380066 seconds, training accuracy = 0.5393219339622641, validation accuracy = 0.5437853107344632\n",
      "Epoch 2: curr_epoch_loss=0.6702501368522644, running time = 20.72607684135437 seconds, training accuracy = 0.6131957547169812, validation accuracy = 0.5536723163841808\n",
      "Epoch 3: curr_epoch_loss=0.6269019103050232, running time = 20.595781087875366 seconds, training accuracy = 0.6490477594339623, validation accuracy = 0.615819209039548\n",
      "Epoch 4: curr_epoch_loss=0.5814765131473542, running time = 20.661156177520752 seconds, training accuracy = 0.7013708726415095, validation accuracy = 0.594632768361582\n",
      "Epoch 5: curr_epoch_loss=0.5156435257196427, running time = 20.61659336090088 seconds, training accuracy = 0.7576326650943396, validation accuracy = 0.6045197740112994\n",
      "Epoch 6: curr_epoch_loss=0.4263259422779083, running time = 20.712053060531616 seconds, training accuracy = 0.8246521226415094, validation accuracy = 0.615819209039548\n",
      "Epoch 7: curr_epoch_loss=0.31049283742904665, running time = 20.60715341567993 seconds, training accuracy = 0.8978007075471699, validation accuracy = 0.6073446327683616\n",
      "Epoch 8: curr_epoch_loss=0.18527796238660812, running time = 20.61725926399231 seconds, training accuracy = 0.9615625, validation accuracy = 0.6186440677966102\n",
      "Epoch 9: curr_epoch_loss=0.09315193675458432, running time = 20.222859144210815 seconds, training accuracy = 0.9932488207547169, validation accuracy = 0.6299435028248588\n",
      "Epoch 10: curr_epoch_loss=0.04456907629966736, running time = 20.132232427597046 seconds, training accuracy = 0.99859375, validation accuracy = 0.6214689265536724\n",
      "Epoch 11: curr_epoch_loss=0.022255952320992946, running time = 20.086055517196655 seconds, training accuracy = 1.0, validation accuracy = 0.6242937853107344\n",
      "Validation Precision: 0.5903954802259888\n",
      "Validation Recall: 0.6333333333333333\n",
      "Validation F1: 0.6111111111111112\n",
      "Validation Accuracy: 0.6242937853107344\n",
      "Empty Cache: Allocated - 0.0/0.0 Cached - 0.0/4318.0\n",
      "---------------------------------------------------------------------------\n",
      "Current Fold:  8\n",
      "---------------------------------------------------------------------------\n",
      "Epoch 1: curr_epoch_loss=0.6912747502326966, running time = 20.185801029205322 seconds, training accuracy = 0.5191391509433962, validation accuracy = 0.536723163841808\n",
      "Epoch 2: curr_epoch_loss=0.66792888879776, running time = 20.197349309921265 seconds, training accuracy = 0.5982930424528302, validation accuracy = 0.6059322033898306\n",
      "Epoch 3: curr_epoch_loss=0.6266286253929139, running time = 20.1407368183136 seconds, training accuracy = 0.6510583726415095, validation accuracy = 0.6299435028248588\n",
      "Epoch 4: curr_epoch_loss=0.5822657930850983, running time = 20.03637933731079 seconds, training accuracy = 0.7011438679245283, validation accuracy = 0.6398305084745762\n",
      "Epoch 5: curr_epoch_loss=0.5227318376302719, running time = 19.745604276657104 seconds, training accuracy = 0.7478862028301887, validation accuracy = 0.6299435028248588\n",
      "Epoch 6: curr_epoch_loss=0.42957582950592044, running time = 20.51655125617981 seconds, training accuracy = 0.8291745283018868, validation accuracy = 0.6454802259887006\n",
      "Epoch 7: curr_epoch_loss=0.30772394478321075, running time = 20.37269353866577 seconds, training accuracy = 0.9048909198113207, validation accuracy = 0.6454802259887006\n",
      "Epoch 8: curr_epoch_loss=0.17778493076562882, running time = 21.024009466171265 seconds, training accuracy = 0.9671816037735849, validation accuracy = 0.6228813559322034\n",
      "Epoch 9: curr_epoch_loss=0.08675072014331818, running time = 21.220492124557495 seconds, training accuracy = 0.9925, validation accuracy = 0.635593220338983\n",
      "Epoch 10: curr_epoch_loss=0.037569404058158395, running time = 20.898980617523193 seconds, training accuracy = 0.9993425707547169, validation accuracy = 0.6228813559322034\n",
      "Epoch 11: curr_epoch_loss=0.01943728478625417, running time = 21.071804761886597 seconds, training accuracy = 0.99953125, validation accuracy = 0.6412429378531074\n",
      "Validation Precision: 0.6977401129943502\n",
      "Validation Recall: 0.6269035532994924\n",
      "Validation F1: 0.660427807486631\n",
      "Validation Accuracy: 0.6412429378531074\n",
      "Empty Cache: Allocated - 0.0/0.0 Cached - 0.0/4318.0\n",
      "---------------------------------------------------------------------------\n",
      "Current Fold:  9\n",
      "---------------------------------------------------------------------------\n",
      "Epoch 1: curr_epoch_loss=0.6918832111358643, running time = 20.66842532157898 seconds, training accuracy = 0.5294722877358491, validation accuracy = 0.6031073446327684\n",
      "Epoch 2: curr_epoch_loss=0.6729349732398987, running time = 20.148320198059082 seconds, training accuracy = 0.6032930424528302, validation accuracy = 0.653954802259887\n",
      "Epoch 3: curr_epoch_loss=0.6287087965011596, running time = 20.469055891036987 seconds, training accuracy = 0.6490860849056603, validation accuracy = 0.6412429378531074\n",
      "Epoch 4: curr_epoch_loss=0.5784506583213807, running time = 20.616416454315186 seconds, training accuracy = 0.7023997641509433, validation accuracy = 0.6370056497175142\n",
      "Epoch 5: curr_epoch_loss=0.5175189328193665, running time = 20.53136897087097 seconds, training accuracy = 0.7520607311320755, validation accuracy = 0.6680790960451978\n",
      "Epoch 6: curr_epoch_loss=0.41649090707302094, running time = 20.687012672424316 seconds, training accuracy = 0.8339740566037736, validation accuracy = 0.6596045197740112\n",
      "Epoch 7: curr_epoch_loss=0.2912862884998322, running time = 20.519782781600952 seconds, training accuracy = 0.9131456367924529, validation accuracy = 0.6412429378531074\n",
      "Epoch 8: curr_epoch_loss=0.16722622513771057, running time = 20.723212957382202 seconds, training accuracy = 0.9702741745283019, validation accuracy = 0.6370056497175142\n",
      "Epoch 9: curr_epoch_loss=0.08062508784234523, running time = 20.668864965438843 seconds, training accuracy = 0.994498820754717, validation accuracy = 0.6271186440677966\n",
      "Epoch 10: curr_epoch_loss=0.036814371645450594, running time = 21.019372701644897 seconds, training accuracy = 0.999375, validation accuracy = 0.6370056497175142\n",
      "Epoch 11: curr_epoch_loss=0.018590009976178407, running time = 20.67811942100525 seconds, training accuracy = 1.0, validation accuracy = 0.6257062146892656\n",
      "Validation Precision: 0.6440677966101694\n",
      "Validation Recall: 0.6212534059945504\n",
      "Validation F1: 0.6324549237170596\n",
      "Validation Accuracy: 0.6257062146892656\n",
      "Empty Cache: Allocated - 0.0/0.0 Cached - 0.0/4318.0\n",
      "---------------------------------------------------------------------------\n",
      "Current Fold:  10\n",
      "---------------------------------------------------------------------------\n",
      "Epoch 1: curr_epoch_loss=0.6929757308959961, running time = 20.951987981796265 seconds, training accuracy = 0.5161409198113208, validation accuracy = 0.5\n",
      "Epoch 2: curr_epoch_loss=0.6789658737182617, running time = 20.967470169067383 seconds, training accuracy = 0.5795430424528302, validation accuracy = 0.5734463276836158\n",
      "Epoch 3: curr_epoch_loss=0.6384149706363678, running time = 20.9891836643219 seconds, training accuracy = 0.6452977594339623, validation accuracy = 0.6186440677966102\n",
      "Epoch 4: curr_epoch_loss=0.6000722658634186, running time = 20.331531763076782 seconds, training accuracy = 0.6803626179245283, validation accuracy = 0.632768361581921\n",
      "Epoch 5: curr_epoch_loss=0.5547625213861466, running time = 20.57075023651123 seconds, training accuracy = 0.7216303066037736, validation accuracy = 0.6285310734463276\n",
      "Epoch 6: curr_epoch_loss=0.47948848247528075, running time = 20.992679834365845 seconds, training accuracy = 0.7912529481132076, validation accuracy = 0.632768361581921\n",
      "Epoch 7: curr_epoch_loss=0.3774509161710739, running time = 20.645228385925293 seconds, training accuracy = 0.8555483490566037, validation accuracy = 0.6214689265536724\n",
      "Epoch 8: curr_epoch_loss=0.2634350460767746, running time = 20.16570472717285 seconds, training accuracy = 0.9211527122641509, validation accuracy = 0.6299435028248588\n",
      "Epoch 9: curr_epoch_loss=0.15374207004904747, running time = 20.39593744277954 seconds, training accuracy = 0.9754952830188679, validation accuracy = 0.6497175141242938\n",
      "Epoch 10: curr_epoch_loss=0.07659971944987774, running time = 19.995039463043213 seconds, training accuracy = 0.995625, validation accuracy = 0.6468926553672316\n",
      "Epoch 11: curr_epoch_loss=0.04077672693878412, running time = 20.001431226730347 seconds, training accuracy = 0.99875, validation accuracy = 0.6257062146892656\n",
      "Validation Precision: 0.6016949152542372\n",
      "Validation Recall: 0.6320474777448071\n",
      "Validation F1: 0.6164978292329956\n",
      "Validation Accuracy: 0.6257062146892656\n",
      "Empty Cache: Allocated - 0.0/0.0 Cached - 0.0/4318.0\n",
      "---------------------------------------------------------------------------\n",
      "Stratified k-fold: Model with 50 features, learning rate 0.0003, dropout_p 0.3, epochs 11, layers [5, 5, 5]\n",
      "Avg Validation Precision: 0.6460555422933079\n",
      "Avg Validation Recall: 0.6458238700324401\n",
      "Avg Validation F1: 0.6441280936292075\n",
      "Avg Validation Accuracy: 0.6439375104587507\n",
      "---------------------------------------------------------------------------\n",
      "Total running time = 2420.99 seconds\n"
     ]
    }
   ],
   "source": [
    "dataset = readmission_gen_dataset\n",
    "tokens_list_gen, sample_labels_list_gen = train_validate_CNN(dataset, weights_matrix, \n",
    "                                                             kfolds = KFOLD_SPLITS, \n",
    "                                                             epochs = 11, \n",
    "                                                             n_features = 50, \n",
    "                                                             dropout_p = 0.3, \n",
    "                                                             learning_rate = 0.0003, \n",
    "                                                             filter_layers=[5, 5, 5], \n",
    "                                                             batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Current Fold:  1\n",
      "---------------------------------------------------------------------------\n",
      "Epoch 1: curr_epoch_loss=0.6933151015213558, running time = 5.449240207672119 seconds, training accuracy = 0.5105277185501066, validation accuracy = 0.49740932642487046\n",
      "Epoch 2: curr_epoch_loss=0.6894278143133435, running time = 5.092603921890259 seconds, training accuracy = 0.5311750399786781, validation accuracy = 0.5181347150259067\n",
      "Epoch 3: curr_epoch_loss=0.6802388344492231, running time = 5.112287759780884 seconds, training accuracy = 0.5675556369936035, validation accuracy = 0.5129533678756477\n",
      "Epoch 4: curr_epoch_loss=0.6673926455633981, running time = 5.1017279624938965 seconds, training accuracy = 0.6282815831556503, validation accuracy = 0.6269430051813472\n",
      "Epoch 5: curr_epoch_loss=0.6385394164494106, running time = 5.110121250152588 seconds, training accuracy = 0.6902235474413646, validation accuracy = 0.6269430051813472\n",
      "Epoch 6: curr_epoch_loss=0.5995296026979174, running time = 5.114880800247192 seconds, training accuracy = 0.7343666711087421, validation accuracy = 0.6683937823834197\n",
      "Epoch 7: curr_epoch_loss=0.5429568333285195, running time = 5.1174046993255615 seconds, training accuracy = 0.7592200826226013, validation accuracy = 0.689119170984456\n",
      "Epoch 8: curr_epoch_loss=0.474273328270231, running time = 5.1430442333221436 seconds, training accuracy = 0.7943263592750532, validation accuracy = 0.6632124352331606\n",
      "Epoch 9: curr_epoch_loss=0.40027294414384024, running time = 5.1284449100494385 seconds, training accuracy = 0.8538862606609808, validation accuracy = 0.6787564766839378\n",
      "Epoch 10: curr_epoch_loss=0.3049634780202593, running time = 5.1220691204071045 seconds, training accuracy = 0.9311034115138593, validation accuracy = 0.6787564766839378\n",
      "Epoch 11: curr_epoch_loss=0.21934619333062852, running time = 5.117534875869751 seconds, training accuracy = 0.9634195095948828, validation accuracy = 0.6632124352331606\n",
      "Validation Precision: 0.7319587628865979\n",
      "Validation Recall: 0.6454545454545455\n",
      "Validation F1: 0.6859903381642511\n",
      "Validation Accuracy: 0.6632124352331606\n",
      "Empty Cache: Allocated - 0.0/0.0 Cached - 0.0/3708.0\n",
      "---------------------------------------------------------------------------\n",
      "Current Fold:  2\n",
      "---------------------------------------------------------------------------\n",
      "Epoch 1: curr_epoch_loss=0.6940834607396807, running time = 5.237826347351074 seconds, training accuracy = 0.492162513326226, validation accuracy = 0.5077720207253886\n",
      "Epoch 2: curr_epoch_loss=0.6857805890696389, running time = 5.1357762813568115 seconds, training accuracy = 0.5629414312366737, validation accuracy = 0.6321243523316062\n",
      "Epoch 3: curr_epoch_loss=0.6704741844109127, running time = 5.148372173309326 seconds, training accuracy = 0.6668360207889126, validation accuracy = 0.5906735751295337\n",
      "Epoch 4: curr_epoch_loss=0.6513935966151101, running time = 5.162179470062256 seconds, training accuracy = 0.6572494669509595, validation accuracy = 0.6113989637305699\n",
      "Epoch 5: curr_epoch_loss=0.6138575971126556, running time = 5.170382976531982 seconds, training accuracy = 0.7121951625799573, validation accuracy = 0.6476683937823834\n",
      "Epoch 6: curr_epoch_loss=0.5625350666897637, running time = 5.183319091796875 seconds, training accuracy = 0.7584121801705758, validation accuracy = 0.6476683937823834\n",
      "Epoch 7: curr_epoch_loss=0.5038328277213233, running time = 5.153420686721802 seconds, training accuracy = 0.7862639925373135, validation accuracy = 0.6373056994818653\n",
      "Epoch 8: curr_epoch_loss=0.4358990362712315, running time = 5.148855209350586 seconds, training accuracy = 0.8308069029850745, validation accuracy = 0.5854922279792746\n",
      "Epoch 9: curr_epoch_loss=0.3608869250331606, running time = 5.152930736541748 seconds, training accuracy = 0.882704224413646, validation accuracy = 0.6010362694300518\n",
      "Epoch 10: curr_epoch_loss=0.26939375166382107, running time = 5.1474854946136475 seconds, training accuracy = 0.9437383395522387, validation accuracy = 0.6424870466321243\n",
      "Epoch 11: curr_epoch_loss=0.1923760590808732, running time = 5.1576988697052 seconds, training accuracy = 0.9706739738805971, validation accuracy = 0.6321243523316062\n",
      "Validation Precision: 0.6185567010309279\n",
      "Validation Recall: 0.6382978723404256\n",
      "Validation F1: 0.6282722513089005\n",
      "Validation Accuracy: 0.6321243523316062\n",
      "Empty Cache: Allocated - 0.0/0.0 Cached - 0.0/3708.0\n",
      "---------------------------------------------------------------------------\n",
      "Current Fold:  3\n",
      "---------------------------------------------------------------------------\n",
      "Epoch 1: curr_epoch_loss=0.6943752127034324, running time = 5.264665603637695 seconds, training accuracy = 0.4932286114072495, validation accuracy = 0.49740932642487046\n",
      "Epoch 2: curr_epoch_loss=0.68794532758849, running time = 5.166211366653442 seconds, training accuracy = 0.556694762793177, validation accuracy = 0.5233160621761658\n",
      "Epoch 3: curr_epoch_loss=0.6765162306172507, running time = 5.145357370376587 seconds, training accuracy = 0.6149386993603411, validation accuracy = 0.5906735751295337\n",
      "Epoch 4: curr_epoch_loss=0.6548106031758445, running time = 5.151402711868286 seconds, training accuracy = 0.6671441897654585, validation accuracy = 0.5440414507772021\n",
      "Epoch 5: curr_epoch_loss=0.6310973933764866, running time = 5.310354709625244 seconds, training accuracy = 0.6541011460554371, validation accuracy = 0.6476683937823834\n",
      "Epoch 6: curr_epoch_loss=0.5816189518996647, running time = 5.351224422454834 seconds, training accuracy = 0.7507496002132196, validation accuracy = 0.6010362694300518\n",
      "Epoch 7: curr_epoch_loss=0.5291921347379684, running time = 5.145430564880371 seconds, training accuracy = 0.7615521721748401, validation accuracy = 0.6269430051813472\n",
      "Epoch 8: curr_epoch_loss=0.46660523968083517, running time = 5.169436454772949 seconds, training accuracy = 0.81254164445629, validation accuracy = 0.6424870466321243\n",
      "Epoch 9: curr_epoch_loss=0.3852074955190931, running time = 5.172595024108887 seconds, training accuracy = 0.8763159648187634, validation accuracy = 0.6580310880829016\n",
      "Epoch 10: curr_epoch_loss=0.29447916575840544, running time = 5.165060758590698 seconds, training accuracy = 0.9338436167377399, validation accuracy = 0.6683937823834197\n",
      "Epoch 11: curr_epoch_loss=0.2055768689938954, running time = 5.153015375137329 seconds, training accuracy = 0.9761044109808102, validation accuracy = 0.6373056994818653\n",
      "Validation Precision: 0.625\n",
      "Validation Recall: 0.6382978723404256\n",
      "Validation F1: 0.631578947368421\n",
      "Validation Accuracy: 0.6373056994818653\n",
      "Empty Cache: Allocated - 0.0/0.0 Cached - 0.0/3708.0\n",
      "---------------------------------------------------------------------------\n",
      "Current Fold:  4\n",
      "---------------------------------------------------------------------------\n",
      "Epoch 1: curr_epoch_loss=0.6908979884215763, running time = 5.266517639160156 seconds, training accuracy = 0.5200726279317698, validation accuracy = 0.5025906735751295\n",
      "Epoch 2: curr_epoch_loss=0.6859588835920606, running time = 5.1614320278167725 seconds, training accuracy = 0.5426855676972282, validation accuracy = 0.5025906735751295\n",
      "Epoch 3: curr_epoch_loss=0.6694667594773429, running time = 5.159908294677734 seconds, training accuracy = 0.5971315298507462, validation accuracy = 0.5440414507772021\n",
      "Epoch 4: curr_epoch_loss=0.6490956587450845, running time = 5.1549601554870605 seconds, training accuracy = 0.7067563965884861, validation accuracy = 0.538860103626943\n",
      "Epoch 5: curr_epoch_loss=0.6182879720415387, running time = 5.155909299850464 seconds, training accuracy = 0.7177255463752665, validation accuracy = 0.5440414507772021\n",
      "Epoch 6: curr_epoch_loss=0.5819365637642997, running time = 5.17005467414856 seconds, training accuracy = 0.7282199493603411, validation accuracy = 0.6321243523316062\n",
      "Epoch 7: curr_epoch_loss=0.5290794095822743, running time = 5.16060471534729 seconds, training accuracy = 0.7624100479744137, validation accuracy = 0.5647668393782384\n",
      "Epoch 8: curr_epoch_loss=0.4668364141668592, running time = 5.160844802856445 seconds, training accuracy = 0.8121335287846482, validation accuracy = 0.6373056994818653\n",
      "Epoch 9: curr_epoch_loss=0.39290623153959003, running time = 5.151425838470459 seconds, training accuracy = 0.8763659381663114, validation accuracy = 0.6321243523316062\n",
      "Epoch 10: curr_epoch_loss=0.31474787848336355, running time = 5.144199371337891 seconds, training accuracy = 0.9132962420042644, validation accuracy = 0.5492227979274611\n",
      "Epoch 11: curr_epoch_loss=0.23204933106899261, running time = 5.160006046295166 seconds, training accuracy = 0.9610374466950959, validation accuracy = 0.5647668393782384\n",
      "Validation Precision: 0.5416666666666666\n",
      "Validation Recall: 0.5652173913043478\n",
      "Validation F1: 0.5531914893617021\n",
      "Validation Accuracy: 0.5647668393782384\n",
      "Empty Cache: Allocated - 0.0/0.0 Cached - 0.0/3708.0\n",
      "---------------------------------------------------------------------------\n",
      "Current Fold:  5\n",
      "---------------------------------------------------------------------------\n",
      "Epoch 1: curr_epoch_loss=0.6931363897664207, running time = 5.251955986022949 seconds, training accuracy = 0.5053177521008403, validation accuracy = 0.515625\n",
      "Epoch 2: curr_epoch_loss=0.6852642595767975, running time = 5.155735492706299 seconds, training accuracy = 0.5779936974789915, validation accuracy = 0.5416666666666666\n",
      "Epoch 3: curr_epoch_loss=0.6722654487405505, running time = 5.131805658340454 seconds, training accuracy = 0.6707589285714286, validation accuracy = 0.5729166666666666\n",
      "Epoch 4: curr_epoch_loss=0.6521997494356973, running time = 5.157286167144775 seconds, training accuracy = 0.6549041491596638, validation accuracy = 0.59375\n",
      "Epoch 5: curr_epoch_loss=0.61861110159329, running time = 5.169119358062744 seconds, training accuracy = 0.7219997373949579, validation accuracy = 0.6197916666666666\n",
      "Epoch 6: curr_epoch_loss=0.5683333192552839, running time = 5.1581711769104 seconds, training accuracy = 0.7464548319327732, validation accuracy = 0.6302083333333334\n",
      "Epoch 7: curr_epoch_loss=0.5227764483009066, running time = 5.147492170333862 seconds, training accuracy = 0.7701877626050421, validation accuracy = 0.6041666666666666\n",
      "Epoch 8: curr_epoch_loss=0.4532694135393415, running time = 5.1572229862213135 seconds, training accuracy = 0.8221507352941176, validation accuracy = 0.609375\n",
      "Epoch 9: curr_epoch_loss=0.3929086668150766, running time = 5.112385988235474 seconds, training accuracy = 0.8520220588235293, validation accuracy = 0.6197916666666666\n",
      "Epoch 10: curr_epoch_loss=0.3116169593163899, running time = 5.151610374450684 seconds, training accuracy = 0.914390756302521, validation accuracy = 0.5989583333333334\n",
      "Epoch 11: curr_epoch_loss=0.23524596861430577, running time = 5.158181428909302 seconds, training accuracy = 0.9646139705882353, validation accuracy = 0.609375\n",
      "Validation Precision: 0.6458333333333334\n",
      "Validation Recall: 0.6019417475728155\n",
      "Validation F1: 0.6231155778894473\n",
      "Validation Accuracy: 0.609375\n",
      "Empty Cache: Allocated - 0.0/0.0 Cached - 0.0/3708.0\n",
      "---------------------------------------------------------------------------\n",
      "Current Fold:  6\n",
      "---------------------------------------------------------------------------\n",
      "Epoch 1: curr_epoch_loss=0.693870335817337, running time = 5.255010604858398 seconds, training accuracy = 0.5096179096638656, validation accuracy = 0.5052083333333334\n",
      "Epoch 2: curr_epoch_loss=0.6812483455453601, running time = 5.163196325302124 seconds, training accuracy = 0.5730698529411765, validation accuracy = 0.5052083333333334\n",
      "Epoch 3: curr_epoch_loss=0.6669595454420362, running time = 5.153928995132446 seconds, training accuracy = 0.641938025210084, validation accuracy = 0.5364583333333334\n",
      "Epoch 4: curr_epoch_loss=0.6411529949733189, running time = 5.159027576446533 seconds, training accuracy = 0.6924566701680673, validation accuracy = 0.5625\n",
      "Epoch 5: curr_epoch_loss=0.6070926061698368, running time = 5.165971517562866 seconds, training accuracy = 0.7033547794117647, validation accuracy = 0.5885416666666666\n",
      "Epoch 6: curr_epoch_loss=0.5639148993151528, running time = 5.162762403488159 seconds, training accuracy = 0.7361147584033613, validation accuracy = 0.5729166666666666\n",
      "Epoch 7: curr_epoch_loss=0.5114162692001888, running time = 5.158954620361328 seconds, training accuracy = 0.7807247899159664, validation accuracy = 0.53125\n",
      "Epoch 8: curr_epoch_loss=0.46446619076388224, running time = 5.148090600967407 seconds, training accuracy = 0.8015034138655462, validation accuracy = 0.5729166666666666\n",
      "Epoch 9: curr_epoch_loss=0.41667786666325163, running time = 5.168126106262207 seconds, training accuracy = 0.8312106092436975, validation accuracy = 0.5572916666666666\n",
      "Epoch 10: curr_epoch_loss=0.3579530098608562, running time = 5.157991409301758 seconds, training accuracy = 0.8591452205882353, validation accuracy = 0.5677083333333334\n",
      "Epoch 11: curr_epoch_loss=0.2863724614892687, running time = 5.153244972229004 seconds, training accuracy = 0.9261751575630253, validation accuracy = 0.5885416666666666\n",
      "Validation Precision: 0.7708333333333334\n",
      "Validation Recall: 0.5648854961832062\n",
      "Validation F1: 0.6519823788546256\n",
      "Validation Accuracy: 0.5885416666666666\n",
      "Empty Cache: Allocated - 0.0/0.0 Cached - 0.0/3708.0\n",
      "---------------------------------------------------------------------------\n",
      "Current Fold:  7\n",
      "---------------------------------------------------------------------------\n",
      "Epoch 1: curr_epoch_loss=0.6934479815619332, running time = 5.251880645751953 seconds, training accuracy = 0.5244879201680672, validation accuracy = 0.5416666666666666\n",
      "Epoch 2: curr_epoch_loss=0.6879726137433734, running time = 5.147434711456299 seconds, training accuracy = 0.5842962184873949, validation accuracy = 0.515625\n",
      "Epoch 3: curr_epoch_loss=0.6790238193103245, running time = 5.1820361614227295 seconds, training accuracy = 0.5898109243697479, validation accuracy = 0.578125\n",
      "Epoch 4: curr_epoch_loss=0.6622911691665649, running time = 5.178011417388916 seconds, training accuracy = 0.6587119222689076, validation accuracy = 0.5364583333333334\n",
      "Epoch 5: curr_epoch_loss=0.6334420101983207, running time = 5.194347858428955 seconds, training accuracy = 0.6955751050420168, validation accuracy = 0.6302083333333334\n",
      "Epoch 6: curr_epoch_loss=0.5967904286725181, running time = 5.194667816162109 seconds, training accuracy = 0.7088038340336135, validation accuracy = 0.6354166666666666\n",
      "Epoch 7: curr_epoch_loss=0.5435326674154827, running time = 5.179086685180664 seconds, training accuracy = 0.7544642857142857, validation accuracy = 0.5989583333333334\n",
      "Epoch 8: curr_epoch_loss=0.47975597424166544, running time = 5.197342157363892 seconds, training accuracy = 0.7922794117647058, validation accuracy = 0.625\n",
      "Epoch 9: curr_epoch_loss=0.4153969330447061, running time = 5.204951047897339 seconds, training accuracy = 0.8430278361344538, validation accuracy = 0.640625\n",
      "Epoch 10: curr_epoch_loss=0.3334002877984728, running time = 5.19387674331665 seconds, training accuracy = 0.8976496848739496, validation accuracy = 0.5989583333333334\n",
      "Epoch 11: curr_epoch_loss=0.24999521246978215, running time = 5.169440746307373 seconds, training accuracy = 0.9516478466386554, validation accuracy = 0.609375\n",
      "Validation Precision: 0.5625\n",
      "Validation Recall: 0.6206896551724138\n",
      "Validation F1: 0.5901639344262296\n",
      "Validation Accuracy: 0.609375\n",
      "Empty Cache: Allocated - 0.0/0.0 Cached - 0.0/3708.0\n",
      "---------------------------------------------------------------------------\n",
      "Current Fold:  8\n",
      "---------------------------------------------------------------------------\n",
      "Epoch 1: curr_epoch_loss=0.692230258669172, running time = 5.242408752441406 seconds, training accuracy = 0.5277048319327731, validation accuracy = 0.5\n",
      "Epoch 2: curr_epoch_loss=0.6869239807128906, running time = 5.177416563034058 seconds, training accuracy = 0.5402770483193277, validation accuracy = 0.515625\n",
      "Epoch 3: curr_epoch_loss=0.677219786814281, running time = 5.158545970916748 seconds, training accuracy = 0.5597426470588235, validation accuracy = 0.5416666666666666\n",
      "Epoch 4: curr_epoch_loss=0.6574137508869171, running time = 5.198254585266113 seconds, training accuracy = 0.6710871848739496, validation accuracy = 0.5833333333333334\n",
      "Epoch 5: curr_epoch_loss=0.6320889507021222, running time = 5.182898283004761 seconds, training accuracy = 0.6900275735294118, validation accuracy = 0.5833333333333334\n",
      "Epoch 6: curr_epoch_loss=0.5953015301908765, running time = 5.1617395877838135 seconds, training accuracy = 0.7103794642857143, validation accuracy = 0.6354166666666666\n",
      "Epoch 7: curr_epoch_loss=0.5467007287911007, running time = 5.144128322601318 seconds, training accuracy = 0.7559414390756303, validation accuracy = 0.6197916666666666\n",
      "Epoch 8: curr_epoch_loss=0.490696913429669, running time = 5.177544116973877 seconds, training accuracy = 0.7927061449579832, validation accuracy = 0.6302083333333334\n",
      "Epoch 9: curr_epoch_loss=0.4274011382034847, running time = 5.18053936958313 seconds, training accuracy = 0.8288471638655462, validation accuracy = 0.640625\n",
      "Epoch 10: curr_epoch_loss=0.35147279713835033, running time = 5.187782526016235 seconds, training accuracy = 0.8859965861344538, validation accuracy = 0.65625\n",
      "Epoch 11: curr_epoch_loss=0.275454723409244, running time = 5.200392961502075 seconds, training accuracy = 0.9338563550420168, validation accuracy = 0.6458333333333334\n",
      "Validation Precision: 0.5520833333333334\n",
      "Validation Recall: 0.6794871794871795\n",
      "Validation F1: 0.6091954022988507\n",
      "Validation Accuracy: 0.6458333333333334\n",
      "Empty Cache: Allocated - 0.0/0.0 Cached - 0.0/3708.0\n",
      "---------------------------------------------------------------------------\n",
      "Current Fold:  9\n",
      "---------------------------------------------------------------------------\n",
      "Epoch 1: curr_epoch_loss=0.6960034072399139, running time = 5.262718915939331 seconds, training accuracy = 0.47547925420168063, validation accuracy = 0.5\n",
      "Epoch 2: curr_epoch_loss=0.692316506590162, running time = 5.161206007003784 seconds, training accuracy = 0.5158219537815126, validation accuracy = 0.5260416666666666\n",
      "Epoch 3: curr_epoch_loss=0.6839711964130402, running time = 5.164827823638916 seconds, training accuracy = 0.5538340336134454, validation accuracy = 0.5989583333333334\n",
      "Epoch 4: curr_epoch_loss=0.674067062991006, running time = 5.161083221435547 seconds, training accuracy = 0.5836068802521008, validation accuracy = 0.6197916666666666\n",
      "Epoch 5: curr_epoch_loss=0.6498612974371228, running time = 5.180498123168945 seconds, training accuracy = 0.6892397584033613, validation accuracy = 0.5989583333333334\n",
      "Epoch 6: curr_epoch_loss=0.6115077223096576, running time = 5.176111698150635 seconds, training accuracy = 0.7341780462184875, validation accuracy = 0.6458333333333334\n",
      "Epoch 7: curr_epoch_loss=0.5624530613422394, running time = 5.159598350524902 seconds, training accuracy = 0.7488182773109244, validation accuracy = 0.640625\n",
      "Epoch 8: curr_epoch_loss=0.4994764987911497, running time = 5.149029016494751 seconds, training accuracy = 0.7910976890756303, validation accuracy = 0.6197916666666666\n",
      "Epoch 9: curr_epoch_loss=0.44030836650303434, running time = 5.15472412109375 seconds, training accuracy = 0.8204766281512604, validation accuracy = 0.6458333333333334\n",
      "Epoch 10: curr_epoch_loss=0.36455890962055754, running time = 5.1506946086883545 seconds, training accuracy = 0.8816636029411765, validation accuracy = 0.6197916666666666\n",
      "Epoch 11: curr_epoch_loss=0.28130218173776356, running time = 5.194593667984009 seconds, training accuracy = 0.9383862920168067, validation accuracy = 0.6302083333333334\n",
      "Validation Precision: 0.5416666666666666\n",
      "Validation Recall: 0.6582278481012658\n",
      "Validation F1: 0.5942857142857143\n",
      "Validation Accuracy: 0.6302083333333334\n",
      "Empty Cache: Allocated - 0.0/0.0 Cached - 0.0/3708.0\n",
      "---------------------------------------------------------------------------\n",
      "Current Fold:  10\n",
      "---------------------------------------------------------------------------\n",
      "Epoch 1: curr_epoch_loss=0.6917397465024676, running time = 5.261713981628418 seconds, training accuracy = 0.5103400735294118, validation accuracy = 0.5\n",
      "Epoch 2: curr_epoch_loss=0.6897092802183968, running time = 5.161275386810303 seconds, training accuracy = 0.5227481617647058, validation accuracy = 0.5052083333333334\n",
      "Epoch 3: curr_epoch_loss=0.6798805466720036, running time = 5.156272649765015 seconds, training accuracy = 0.5958180147058824, validation accuracy = 0.5729166666666666\n",
      "Epoch 4: curr_epoch_loss=0.6635869230542865, running time = 5.176721811294556 seconds, training accuracy = 0.6654411764705882, validation accuracy = 0.625\n",
      "Epoch 5: curr_epoch_loss=0.6410815502916064, running time = 5.177196025848389 seconds, training accuracy = 0.6791294642857143, validation accuracy = 0.5833333333333334\n",
      "Epoch 6: curr_epoch_loss=0.6084887385368347, running time = 5.151917219161987 seconds, training accuracy = 0.7033219537815125, validation accuracy = 0.5885416666666666\n",
      "Epoch 7: curr_epoch_loss=0.5605481224400657, running time = 5.160018682479858 seconds, training accuracy = 0.7393973214285714, validation accuracy = 0.6302083333333334\n",
      "Epoch 8: curr_epoch_loss=0.506094434431621, running time = 5.163213491439819 seconds, training accuracy = 0.7784598214285714, validation accuracy = 0.6458333333333334\n",
      "Epoch 9: curr_epoch_loss=0.44417243131569456, running time = 5.136138916015625 seconds, training accuracy = 0.8336068802521008, validation accuracy = 0.6354166666666666\n",
      "Epoch 10: curr_epoch_loss=0.3671373895236424, running time = 5.183606386184692 seconds, training accuracy = 0.8803505777310924, validation accuracy = 0.640625\n",
      "Epoch 11: curr_epoch_loss=0.28465187762464794, running time = 5.168828725814819 seconds, training accuracy = 0.9342174369747899, validation accuracy = 0.6510416666666666\n",
      "Validation Precision: 0.6458333333333334\n",
      "Validation Recall: 0.6526315789473685\n",
      "Validation F1: 0.6492146596858639\n",
      "Validation Accuracy: 0.6510416666666666\n",
      "Empty Cache: Allocated - 0.0/0.0 Cached - 0.0/3708.0\n",
      "---------------------------------------------------------------------------\n",
      "Stratified k-fold: Model with 50 features, learning rate 0.0003, dropout_p 0.3, epochs 11, layers [5, 5, 5]\n",
      "Avg Validation Precision: 0.6235932130584192\n",
      "Avg Validation Recall: 0.6265131186903994\n",
      "Avg Validation F1: 0.6216990693644007\n",
      "Avg Validation Accuracy: 0.623178432642487\n",
      "---------------------------------------------------------------------------\n",
      "Total running time = 573.65 seconds\n"
     ]
    }
   ],
   "source": [
    "dataset = readmission_30day_dataset\n",
    "tokens_list_30day, sample_labels_list_30day = train_validate_CNN(dataset, weights_matrix, \n",
    "                                                                 kfolds = KFOLD_SPLITS, \n",
    "                                                                 epochs = 11, \n",
    "                                                                 n_features = 50, \n",
    "                                                                 dropout_p = 0.3, \n",
    "                                                                 learning_rate = 0.0003, \n",
    "                                                                 filter_layers=[5, 5, 5], \n",
    "                                                                 batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1) Datasets for Random Forest\n",
    "These datasets are the same as used for the CNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1) Load Datasets from Pre-Processed Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed datasets\n",
    "HF_GEN_READMISSIONS_WNOTES = pd.read_pickle(\"./positive_gen_readmissions.pkl.gz\", compression=\"gzip\")\n",
    "HF_NO_GEN_READMISSIONS_WNOTES = pd.read_pickle(\"./negative_gen_readmissions.pkl.gz\", compression=\"gzip\")\n",
    "\n",
    "HF_30DAY_READMISSIONS_WNOTES = pd.read_pickle(\"./positive_30day_readmissions.pkl.gz\", compression=\"gzip\")\n",
    "HF_NO_30DAY_READMISSIONS_WNOTES = pd.read_pickle(\"./negative_30day_readmissions.pkl.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2) Combine Positive and Negative Sample Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30-Day Readmission:  962  +  962  =  1924\n"
     ]
    }
   ],
   "source": [
    "readmission_gen_df = pd.concat([HF_GEN_READMISSIONS_WNOTES, HF_NO_GEN_READMISSIONS_WNOTES])\n",
    "readmission_30day_df = pd.concat([HF_30DAY_READMISSIONS_WNOTES, HF_NO_30DAY_READMISSIONS_WNOTES])\n",
    "\n",
    "print(\"General Readmission: \", len(HF_GEN_READMISSIONS_WNOTES), \" + \", len(HF_NO_GEN_READMISSIONS_WNOTES), \" = \", len(readmission_gen_df))\n",
    "print(\"30-Day Readmission: \", len(HF_30DAY_READMISSIONS_WNOTES), \" + \", len(HF_NO_30DAY_READMISSIONS_WNOTES), \" = \", len(readmission_30day_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3) Transform Dataframe into Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1924,)\n"
     ]
    }
   ],
   "source": [
    "# Text Token Vectors\n",
    "readmission_gen_tensor_tokens = np.array(readmission_gen_df['TEXT'])\n",
    "readmission_30day_tensor_tokens = np.array(readmission_30day_df['TEXT'])\n",
    "\n",
    "print(readmission_gen_tensor_tokens.shape)\n",
    "print(readmission_30day_tensor_tokens.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4) Create Labels for Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1924])\n"
     ]
    }
   ],
   "source": [
    "readmission_gen_labels = torch.cat(\n",
    "    (\n",
    "        torch.ones((len(HF_GEN_READMISSIONS_WNOTES),)), \n",
    "        torch.zeros((len(HF_NO_GEN_READMISSIONS_WNOTES),))\n",
    "    )\n",
    ")\n",
    "readmission_30day_labels = torch.cat(\n",
    "    (\n",
    "        torch.ones((len(HF_30DAY_READMISSIONS_WNOTES),)), \n",
    "        torch.zeros((len(HF_NO_30DAY_READMISSIONS_WNOTES),))\n",
    "    )\n",
    ")\n",
    "\n",
    "print(readmission_gen_labels.shape)\n",
    "print(readmission_30day_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2) Feature Weighting through Term Frequency - Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1) Setup Variable Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = [10000, 15000, 20000, 25000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2) Create Function to Use Pre-Tokenized Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_original(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3) Create TD-IDF Mapping for Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_tfidf(dataset_tokens, features = MAX_FEATURES, tokenizer = return_original, preprocessor = return_original):\n",
    "    dataset_tfidf = {}\n",
    "    for max_ft in features:\n",
    "        vectorizer = TfidfVectorizer(max_features=max_ft, tokenizer=tokenizer, preprocessor=preprocessor)\n",
    "        dataset_tfidf[max_ft] = vectorizer.fit_transform(dataset_tokens)\n",
    "    return dataset_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "readmission_gen_tfidf = create_dataset_tfidf(readmission_gen_tensor_tokens)\n",
    "readmission_30day_tfidf = create_dataset_tfidf(readmission_30day_tensor_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3) Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1) Create Training and Test Sets\n",
    "\n",
    "Use same split as CNN model. Features are TD-IDF weights of individual words instead of word vectors from pre-trained Word2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRFDataset(dataset, labels, train_index, val_index):\n",
    "    X_train, X_test = dataset[train_index], labels[train_index]\n",
    "    y_train, y_test = dataset[val_index], labels[val_index]\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2) Evaluate Random Forest Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalRFMetrics(truth, prediction):\n",
    "    prec_30day = precision_score(truth, prediction, zero_division=0)\n",
    "    recall_30day = recall_score(truth, prediction, zero_division=0)\n",
    "    f1_30day = f1_score(truth, prediction, zero_division=0)\n",
    "    acc_30day = accuracy_score(truth, prediction)\n",
    "\n",
    "    print((\"Validation Precision: \" + str(prec_30day)))\n",
    "    print((\"Validation Recall: \" + str(recall_30day)))\n",
    "    print((\"Validation F1: \" + str(f1_30day)))\n",
    "    print((\"Validation Accuracy: \" + str(acc_30day)))\n",
    "\n",
    "    return [prec_30day, recall_30day, f1_30day, acc_30day]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3) Train and Evaluate Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "KFOLD_SPLITS = 10\n",
    "\n",
    "def train_validate_randomForest(dataset_tfidf, labels, n_splits=KFOLD_SPLITS, shuffle=True, estimators=100, depth=None):\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=shuffle)\n",
    "\n",
    "    for max_ft in dataset_tfidf:\n",
    "        start_runtime = time.time()\n",
    "        metrics = []\n",
    "        for fold_idx, (train_index, val_index) in enumerate(kf.split(dataset_tfidf[max_ft], labels)):\n",
    "            print(\"---------------------------------------------------------------------------\")\n",
    "            print(f\"Features: {max_ft}, Current Fold: {fold_idx+1}, depth {depth}, estimators {estimators}\")\n",
    "            print(\"---------------------------------------------------------------------------\")\n",
    "            # Get datasets for fold\n",
    "            (X_train, X_test, y_train, y_test) = getRFDataset(dataset_tfidf[max_ft], labels, train_index, val_index)\n",
    "            # Initialize random forest model\n",
    "            clf = RandomForestClassifier(n_estimators=estimators, max_depth=depth, random_state=0, max_features=max_ft)\n",
    "            # Train random forest model\n",
    "            clf.fit(X_train, X_test)\n",
    "            # Test random forest model\n",
    "            y_pred = clf.predict(y_train)\n",
    "            # Evaluate random forest model\n",
    "            metrics.append(evalRFMetrics(y_test, y_pred))\n",
    "        \n",
    "        # Calculate cross-validation averaged evaluation metrics\n",
    "        avg_results = np.sum(metrics, axis=0)/float(KFOLD_SPLITS)\n",
    "        print(\"---------------------------------------------------------------------------\")\n",
    "        print(f\"Stratified k-fold: Random Forest with {max_ft} features, depth {depth}, estimators {estimators}\")\n",
    "        print((\"Avg Validation Precision: \" + str(avg_results[0])))\n",
    "        print((\"Avg Validation Recall: \" + str(avg_results[1])))\n",
    "        print((\"Avg Validation F1: \" + str(avg_results[2])))\n",
    "        print((\"Avg Validation Accuracy: \" + str(avg_results[3])))\n",
    "        print(\"---------------------------------------------------------------------------\")\n",
    "        # Get total run time\n",
    "        print(\"Total running time = {:.2f} seconds\".format(time.time() - start_runtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Features: 10000, Current Fold: 1, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6348837209302326\n",
      "Validation Recall: 0.7690140845070422\n",
      "Validation F1: 0.6955414012738853\n",
      "Validation Accuracy: 0.6629055007052186\n",
      "---------------------------------------------------------------------------\n",
      "Features: 10000, Current Fold: 2, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6258205689277899\n",
      "Validation Recall: 0.8056338028169014\n",
      "Validation F1: 0.7044334975369457\n",
      "Validation Accuracy: 0.6614950634696756\n",
      "---------------------------------------------------------------------------\n",
      "Features: 10000, Current Fold: 3, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6367816091954023\n",
      "Validation Recall: 0.780281690140845\n",
      "Validation F1: 0.7012658227848101\n",
      "Validation Accuracy: 0.6671368124118476\n",
      "---------------------------------------------------------------------------\n",
      "Features: 10000, Current Fold: 4, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6454545454545455\n",
      "Validation Recall: 0.8022598870056498\n",
      "Validation F1: 0.7153652392947104\n",
      "Validation Accuracy: 0.6812411847672779\n",
      "---------------------------------------------------------------------------\n",
      "Features: 10000, Current Fold: 5, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6255506607929515\n",
      "Validation Recall: 0.8022598870056498\n",
      "Validation F1: 0.702970297029703\n",
      "Validation Accuracy: 0.6614950634696756\n",
      "---------------------------------------------------------------------------\n",
      "Features: 10000, Current Fold: 6, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6162528216704289\n",
      "Validation Recall: 0.7711864406779662\n",
      "Validation F1: 0.6850690087829361\n",
      "Validation Accuracy: 0.6459802538787024\n",
      "---------------------------------------------------------------------------\n",
      "Features: 10000, Current Fold: 7, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6057268722466961\n",
      "Validation Recall: 0.7768361581920904\n",
      "Validation F1: 0.6806930693069307\n",
      "Validation Accuracy: 0.635593220338983\n",
      "---------------------------------------------------------------------------\n",
      "Features: 10000, Current Fold: 8, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.625\n",
      "Validation Recall: 0.847457627118644\n",
      "Validation F1: 0.7194244604316545\n",
      "Validation Accuracy: 0.6694915254237288\n",
      "---------------------------------------------------------------------------\n",
      "Features: 10000, Current Fold: 9, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.636150234741784\n",
      "Validation Recall: 0.7655367231638418\n",
      "Validation F1: 0.6948717948717948\n",
      "Validation Accuracy: 0.6638418079096046\n",
      "---------------------------------------------------------------------------\n",
      "Features: 10000, Current Fold: 10, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6422018348623854\n",
      "Validation Recall: 0.7909604519774012\n",
      "Validation F1: 0.7088607594936709\n",
      "Validation Accuracy: 0.6751412429378532\n",
      "---------------------------------------------------------------------------\n",
      "Stratified k-fold: Random Forest with 10000 features, depth 5, estimators 100\n",
      "Avg Validation Precision: 0.6293822868822216\n",
      "Avg Validation Recall: 0.791142675260603\n",
      "Avg Validation F1: 0.7008495350807042\n",
      "Avg Validation Accuracy: 0.6624321675312568\n",
      "---------------------------------------------------------------------------\n",
      "Total running time = 902.69 seconds\n",
      "---------------------------------------------------------------------------\n",
      "Features: 15000, Current Fold: 1, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6281179138321995\n",
      "Validation Recall: 0.780281690140845\n",
      "Validation F1: 0.6959798994974873\n",
      "Validation Accuracy: 0.6586741889985895\n",
      "---------------------------------------------------------------------------\n",
      "Features: 15000, Current Fold: 2, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6735632183908046\n",
      "Validation Recall: 0.8253521126760563\n",
      "Validation F1: 0.7417721518987342\n",
      "Validation Accuracy: 0.7122708039492243\n",
      "---------------------------------------------------------------------------\n",
      "Features: 15000, Current Fold: 3, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6257928118393234\n",
      "Validation Recall: 0.8338028169014085\n",
      "Validation F1: 0.714975845410628\n",
      "Validation Accuracy: 0.6671368124118476\n",
      "---------------------------------------------------------------------------\n",
      "Features: 15000, Current Fold: 4, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6152173913043478\n",
      "Validation Recall: 0.7994350282485876\n",
      "Validation F1: 0.6953316953316954\n",
      "Validation Accuracy: 0.6502115655853314\n",
      "---------------------------------------------------------------------------\n",
      "Features: 15000, Current Fold: 5, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6053811659192825\n",
      "Validation Recall: 0.7627118644067796\n",
      "Validation F1: 0.675\n",
      "Validation Accuracy: 0.6332863187588152\n",
      "---------------------------------------------------------------------------\n",
      "Features: 15000, Current Fold: 6, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6347438752783965\n",
      "Validation Recall: 0.8050847457627118\n",
      "Validation F1: 0.709838107098381\n",
      "Validation Accuracy: 0.6713681241184767\n",
      "---------------------------------------------------------------------------\n",
      "Features: 15000, Current Fold: 7, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6306306306306306\n",
      "Validation Recall: 0.7909604519774012\n",
      "Validation F1: 0.7017543859649122\n",
      "Validation Accuracy: 0.6638418079096046\n",
      "---------------------------------------------------------------------------\n",
      "Features: 15000, Current Fold: 8, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6514161220043573\n",
      "Validation Recall: 0.844632768361582\n",
      "Validation F1: 0.7355473554735548\n",
      "Validation Accuracy: 0.6963276836158192\n",
      "---------------------------------------------------------------------------\n",
      "Features: 15000, Current Fold: 9, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6292906178489702\n",
      "Validation Recall: 0.7768361581920904\n",
      "Validation F1: 0.6953223767383059\n",
      "Validation Accuracy: 0.6596045197740112\n",
      "---------------------------------------------------------------------------\n",
      "Features: 15000, Current Fold: 10, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.5949367088607594\n",
      "Validation Recall: 0.7966101694915254\n",
      "Validation F1: 0.681159420289855\n",
      "Validation Accuracy: 0.6271186440677966\n",
      "---------------------------------------------------------------------------\n",
      "Stratified k-fold: Random Forest with 15000 features, depth 5, estimators 100\n",
      "Avg Validation Precision: 0.6289090455909071\n",
      "Avg Validation Recall: 0.8015707806158989\n",
      "Avg Validation F1: 0.7046681237703554\n",
      "Avg Validation Accuracy: 0.6639840469189517\n",
      "---------------------------------------------------------------------------\n",
      "Total running time = 928.17 seconds\n",
      "---------------------------------------------------------------------------\n",
      "Features: 20000, Current Fold: 1, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6754807692307693\n",
      "Validation Recall: 0.7915492957746478\n",
      "Validation F1: 0.7289234760051881\n",
      "Validation Accuracy: 0.7052186177715092\n",
      "---------------------------------------------------------------------------\n",
      "Features: 20000, Current Fold: 2, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6316964285714286\n",
      "Validation Recall: 0.7971830985915493\n",
      "Validation F1: 0.7048567870485679\n",
      "Validation Accuracy: 0.6657263751763046\n",
      "---------------------------------------------------------------------------\n",
      "Features: 20000, Current Fold: 3, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6263498920086393\n",
      "Validation Recall: 0.8169014084507042\n",
      "Validation F1: 0.7090464547677262\n",
      "Validation Accuracy: 0.6643159379407616\n",
      "---------------------------------------------------------------------------\n",
      "Features: 20000, Current Fold: 4, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6298701298701299\n",
      "Validation Recall: 0.8220338983050848\n",
      "Validation F1: 0.7132352941176471\n",
      "Validation Accuracy: 0.6699576868829337\n",
      "---------------------------------------------------------------------------\n",
      "Features: 20000, Current Fold: 5, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6150341685649203\n",
      "Validation Recall: 0.7627118644067796\n",
      "Validation F1: 0.6809583858764187\n",
      "Validation Accuracy: 0.6431593794076164\n",
      "---------------------------------------------------------------------------\n",
      "Features: 20000, Current Fold: 6, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6297117516629712\n",
      "Validation Recall: 0.8022598870056498\n",
      "Validation F1: 0.7055900621118013\n",
      "Validation Accuracy: 0.6657263751763046\n",
      "---------------------------------------------------------------------------\n",
      "Features: 20000, Current Fold: 7, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6252771618625277\n",
      "Validation Recall: 0.7966101694915254\n",
      "Validation F1: 0.7006211180124223\n",
      "Validation Accuracy: 0.6596045197740112\n",
      "---------------------------------------------------------------------------\n",
      "Features: 20000, Current Fold: 8, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6187214611872146\n",
      "Validation Recall: 0.7655367231638418\n",
      "Validation F1: 0.6843434343434344\n",
      "Validation Accuracy: 0.6468926553672316\n",
      "---------------------------------------------------------------------------\n",
      "Features: 20000, Current Fold: 9, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6283783783783784\n",
      "Validation Recall: 0.788135593220339\n",
      "Validation F1: 0.6992481203007519\n",
      "Validation Accuracy: 0.6610169491525424\n",
      "---------------------------------------------------------------------------\n",
      "Features: 20000, Current Fold: 10, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6309523809523809\n",
      "Validation Recall: 0.748587570621469\n",
      "Validation F1: 0.6847545219638244\n",
      "Validation Accuracy: 0.655367231638418\n",
      "---------------------------------------------------------------------------\n",
      "Stratified k-fold: Random Forest with 20000 features, depth 5, estimators 100\n",
      "Avg Validation Precision: 0.6311472522289361\n",
      "Avg Validation Recall: 0.789150950903159\n",
      "Avg Validation F1: 0.7011577654547781\n",
      "Avg Validation Accuracy: 0.6636985728287634\n",
      "---------------------------------------------------------------------------\n",
      "Total running time = 944.46 seconds\n",
      "---------------------------------------------------------------------------\n",
      "Features: 25000, Current Fold: 1, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6181434599156118\n",
      "Validation Recall: 0.8253521126760563\n",
      "Validation F1: 0.7068757539203859\n",
      "Validation Accuracy: 0.6572637517630465\n",
      "---------------------------------------------------------------------------\n",
      "Features: 25000, Current Fold: 2, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.632420091324201\n",
      "Validation Recall: 0.780281690140845\n",
      "Validation F1: 0.6986128625472888\n",
      "Validation Accuracy: 0.6629055007052186\n",
      "---------------------------------------------------------------------------\n",
      "Features: 25000, Current Fold: 3, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6334056399132321\n",
      "Validation Recall: 0.8225352112676056\n",
      "Validation F1: 0.7156862745098038\n",
      "Validation Accuracy: 0.6727785613540197\n",
      "---------------------------------------------------------------------------\n",
      "Features: 25000, Current Fold: 4, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6140776699029126\n",
      "Validation Recall: 0.7146892655367232\n",
      "Validation F1: 0.6605744125326369\n",
      "Validation Accuracy: 0.6332863187588152\n",
      "---------------------------------------------------------------------------\n",
      "Features: 25000, Current Fold: 5, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6486486486486487\n",
      "Validation Recall: 0.8135593220338984\n",
      "Validation F1: 0.7218045112781954\n",
      "Validation Accuracy: 0.68688293370945\n",
      "---------------------------------------------------------------------------\n",
      "Features: 25000, Current Fold: 6, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6278026905829597\n",
      "Validation Recall: 0.7909604519774012\n",
      "Validation F1: 0.7\n",
      "Validation Accuracy: 0.6614950634696756\n",
      "---------------------------------------------------------------------------\n",
      "Features: 25000, Current Fold: 7, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6164383561643836\n",
      "Validation Recall: 0.7627118644067796\n",
      "Validation F1: 0.6818181818181819\n",
      "Validation Accuracy: 0.6440677966101694\n",
      "---------------------------------------------------------------------------\n",
      "Features: 25000, Current Fold: 8, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6229885057471264\n",
      "Validation Recall: 0.7655367231638418\n",
      "Validation F1: 0.6869455006337135\n",
      "Validation Accuracy: 0.6511299435028248\n",
      "---------------------------------------------------------------------------\n",
      "Features: 25000, Current Fold: 9, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6447058823529411\n",
      "Validation Recall: 0.7740112994350282\n",
      "Validation F1: 0.7034659820282413\n",
      "Validation Accuracy: 0.673728813559322\n",
      "---------------------------------------------------------------------------\n",
      "Features: 25000, Current Fold: 10, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6247288503253796\n",
      "Validation Recall: 0.8135593220338984\n",
      "Validation F1: 0.7067484662576687\n",
      "Validation Accuracy: 0.6624293785310734\n",
      "---------------------------------------------------------------------------\n",
      "Stratified k-fold: Random Forest with 25000 features, depth 5, estimators 100\n",
      "Avg Validation Precision: 0.6283359794877397\n",
      "Avg Validation Recall: 0.7863197262672077\n",
      "Avg Validation F1: 0.6982531945526117\n",
      "Avg Validation Accuracy: 0.6605968061963614\n",
      "---------------------------------------------------------------------------\n",
      "Total running time = 960.58 seconds\n"
     ]
    }
   ],
   "source": [
    "dataset_tfidf, labels = readmission_gen_tfidf, readmission_gen_labels\n",
    "train_validate_randomForest(dataset_tfidf, labels, n_splits=KFOLD_SPLITS, shuffle=True, estimators=100, depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Features: 10000, Current Fold: 1, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6634615384615384\n",
      "Validation Recall: 0.711340206185567\n",
      "Validation F1: 0.6865671641791045\n",
      "Validation Accuracy: 0.6735751295336787\n",
      "---------------------------------------------------------------------------\n",
      "Features: 10000, Current Fold: 2, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.646551724137931\n",
      "Validation Recall: 0.7731958762886598\n",
      "Validation F1: 0.7042253521126761\n",
      "Validation Accuracy: 0.6735751295336787\n",
      "---------------------------------------------------------------------------\n",
      "Features: 10000, Current Fold: 3, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6370967741935484\n",
      "Validation Recall: 0.8229166666666666\n",
      "Validation F1: 0.7181818181818183\n",
      "Validation Accuracy: 0.6787564766839378\n",
      "---------------------------------------------------------------------------\n",
      "Features: 10000, Current Fold: 4, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.584070796460177\n",
      "Validation Recall: 0.6875\n",
      "Validation F1: 0.6315789473684211\n",
      "Validation Accuracy: 0.6010362694300518\n",
      "---------------------------------------------------------------------------\n",
      "Features: 10000, Current Fold: 5, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6517857142857143\n",
      "Validation Recall: 0.7604166666666666\n",
      "Validation F1: 0.7019230769230769\n",
      "Validation Accuracy: 0.6770833333333334\n",
      "---------------------------------------------------------------------------\n",
      "Features: 10000, Current Fold: 6, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6346153846153846\n",
      "Validation Recall: 0.6875\n",
      "Validation F1: 0.6599999999999999\n",
      "Validation Accuracy: 0.6458333333333334\n",
      "---------------------------------------------------------------------------\n",
      "Features: 10000, Current Fold: 7, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6696428571428571\n",
      "Validation Recall: 0.78125\n",
      "Validation F1: 0.721153846153846\n",
      "Validation Accuracy: 0.6979166666666666\n",
      "---------------------------------------------------------------------------\n",
      "Features: 10000, Current Fold: 8, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.719626168224299\n",
      "Validation Recall: 0.8020833333333334\n",
      "Validation F1: 0.7586206896551725\n",
      "Validation Accuracy: 0.7447916666666666\n",
      "---------------------------------------------------------------------------\n",
      "Features: 10000, Current Fold: 9, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6173913043478261\n",
      "Validation Recall: 0.7395833333333334\n",
      "Validation F1: 0.6729857819905213\n",
      "Validation Accuracy: 0.640625\n",
      "---------------------------------------------------------------------------\n",
      "Features: 10000, Current Fold: 10, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6347826086956522\n",
      "Validation Recall: 0.7604166666666666\n",
      "Validation F1: 0.6919431279620853\n",
      "Validation Accuracy: 0.6614583333333334\n",
      "---------------------------------------------------------------------------\n",
      "Stratified k-fold: Random Forest with 10000 features, depth 5, estimators 100\n",
      "Avg Validation Precision: 0.6459024870564929\n",
      "Avg Validation Recall: 0.7526202749140893\n",
      "Avg Validation F1: 0.6947179804526722\n",
      "Avg Validation Accuracy: 0.6694651338514681\n",
      "---------------------------------------------------------------------------\n",
      "Total running time = 235.95 seconds\n",
      "---------------------------------------------------------------------------\n",
      "Features: 15000, Current Fold: 1, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.616822429906542\n",
      "Validation Recall: 0.6804123711340206\n",
      "Validation F1: 0.6470588235294117\n",
      "Validation Accuracy: 0.6269430051813472\n",
      "---------------------------------------------------------------------------\n",
      "Features: 15000, Current Fold: 2, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6446280991735537\n",
      "Validation Recall: 0.8041237113402062\n",
      "Validation F1: 0.7155963302752294\n",
      "Validation Accuracy: 0.6787564766839378\n",
      "---------------------------------------------------------------------------\n",
      "Features: 15000, Current Fold: 3, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6403508771929824\n",
      "Validation Recall: 0.7604166666666666\n",
      "Validation F1: 0.6952380952380952\n",
      "Validation Accuracy: 0.6683937823834197\n",
      "---------------------------------------------------------------------------\n",
      "Features: 15000, Current Fold: 4, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6576576576576577\n",
      "Validation Recall: 0.7604166666666666\n",
      "Validation F1: 0.7053140096618357\n",
      "Validation Accuracy: 0.6839378238341969\n",
      "---------------------------------------------------------------------------\n",
      "Features: 15000, Current Fold: 5, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6862745098039216\n",
      "Validation Recall: 0.7291666666666666\n",
      "Validation F1: 0.7070707070707071\n",
      "Validation Accuracy: 0.6979166666666666\n",
      "---------------------------------------------------------------------------\n",
      "Features: 15000, Current Fold: 6, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6111111111111112\n",
      "Validation Recall: 0.6875\n",
      "Validation F1: 0.6470588235294118\n",
      "Validation Accuracy: 0.625\n",
      "---------------------------------------------------------------------------\n",
      "Features: 15000, Current Fold: 7, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6476190476190476\n",
      "Validation Recall: 0.7083333333333334\n",
      "Validation F1: 0.6766169154228856\n",
      "Validation Accuracy: 0.6614583333333334\n",
      "---------------------------------------------------------------------------\n",
      "Features: 15000, Current Fold: 8, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6869565217391305\n",
      "Validation Recall: 0.8229166666666666\n",
      "Validation F1: 0.7488151658767772\n",
      "Validation Accuracy: 0.7239583333333334\n",
      "---------------------------------------------------------------------------\n",
      "Features: 15000, Current Fold: 9, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6475409836065574\n",
      "Validation Recall: 0.8229166666666666\n",
      "Validation F1: 0.7247706422018348\n",
      "Validation Accuracy: 0.6875\n",
      "---------------------------------------------------------------------------\n",
      "Features: 15000, Current Fold: 10, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6126126126126126\n",
      "Validation Recall: 0.7083333333333334\n",
      "Validation F1: 0.6570048309178743\n",
      "Validation Accuracy: 0.6302083333333334\n",
      "---------------------------------------------------------------------------\n",
      "Stratified k-fold: Random Forest with 15000 features, depth 5, estimators 100\n",
      "Avg Validation Precision: 0.6451573850423117\n",
      "Avg Validation Recall: 0.7484536082474227\n",
      "Avg Validation F1: 0.6924544343724065\n",
      "Avg Validation Accuracy: 0.6684072754749567\n",
      "---------------------------------------------------------------------------\n",
      "Total running time = 245.30 seconds\n",
      "---------------------------------------------------------------------------\n",
      "Features: 20000, Current Fold: 1, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.66\n",
      "Validation Recall: 0.6804123711340206\n",
      "Validation F1: 0.6700507614213199\n",
      "Validation Accuracy: 0.6632124352331606\n",
      "---------------------------------------------------------------------------\n",
      "Features: 20000, Current Fold: 2, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6545454545454545\n",
      "Validation Recall: 0.7422680412371134\n",
      "Validation F1: 0.6956521739130435\n",
      "Validation Accuracy: 0.6735751295336787\n",
      "---------------------------------------------------------------------------\n",
      "Features: 20000, Current Fold: 3, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6299212598425197\n",
      "Validation Recall: 0.8333333333333334\n",
      "Validation F1: 0.7174887892376682\n",
      "Validation Accuracy: 0.6735751295336787\n",
      "---------------------------------------------------------------------------\n",
      "Features: 20000, Current Fold: 4, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6698113207547169\n",
      "Validation Recall: 0.7395833333333334\n",
      "Validation F1: 0.702970297029703\n",
      "Validation Accuracy: 0.689119170984456\n",
      "---------------------------------------------------------------------------\n",
      "Features: 20000, Current Fold: 5, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6363636363636364\n",
      "Validation Recall: 0.8020833333333334\n",
      "Validation F1: 0.7096774193548386\n",
      "Validation Accuracy: 0.671875\n",
      "---------------------------------------------------------------------------\n",
      "Features: 20000, Current Fold: 6, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6574074074074074\n",
      "Validation Recall: 0.7395833333333334\n",
      "Validation F1: 0.696078431372549\n",
      "Validation Accuracy: 0.6770833333333334\n",
      "---------------------------------------------------------------------------\n",
      "Features: 20000, Current Fold: 7, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6548672566371682\n",
      "Validation Recall: 0.7708333333333334\n",
      "Validation F1: 0.7081339712918661\n",
      "Validation Accuracy: 0.6822916666666666\n",
      "---------------------------------------------------------------------------\n",
      "Features: 20000, Current Fold: 8, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.5980392156862745\n",
      "Validation Recall: 0.6354166666666666\n",
      "Validation F1: 0.6161616161616161\n",
      "Validation Accuracy: 0.6041666666666666\n",
      "---------------------------------------------------------------------------\n",
      "Features: 20000, Current Fold: 9, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.625\n",
      "Validation Recall: 0.78125\n",
      "Validation F1: 0.6944444444444444\n",
      "Validation Accuracy: 0.65625\n",
      "---------------------------------------------------------------------------\n",
      "Features: 20000, Current Fold: 10, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6868686868686869\n",
      "Validation Recall: 0.7083333333333334\n",
      "Validation F1: 0.6974358974358974\n",
      "Validation Accuracy: 0.6927083333333334\n",
      "---------------------------------------------------------------------------\n",
      "Stratified k-fold: Random Forest with 20000 features, depth 5, estimators 100\n",
      "Avg Validation Precision: 0.6472824238105864\n",
      "Avg Validation Recall: 0.74330970790378\n",
      "Avg Validation F1: 0.6908093801662947\n",
      "Avg Validation Accuracy: 0.6683856865284974\n",
      "---------------------------------------------------------------------------\n",
      "Total running time = 254.76 seconds\n",
      "---------------------------------------------------------------------------\n",
      "Features: 25000, Current Fold: 1, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6548672566371682\n",
      "Validation Recall: 0.7628865979381443\n",
      "Validation F1: 0.7047619047619047\n",
      "Validation Accuracy: 0.6787564766839378\n",
      "---------------------------------------------------------------------------\n",
      "Features: 25000, Current Fold: 2, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6454545454545455\n",
      "Validation Recall: 0.7319587628865979\n",
      "Validation F1: 0.6859903381642511\n",
      "Validation Accuracy: 0.6632124352331606\n",
      "---------------------------------------------------------------------------\n",
      "Features: 25000, Current Fold: 3, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.7102803738317757\n",
      "Validation Recall: 0.7916666666666666\n",
      "Validation F1: 0.7487684729064038\n",
      "Validation Accuracy: 0.7357512953367875\n",
      "---------------------------------------------------------------------------\n",
      "Features: 25000, Current Fold: 4, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6016949152542372\n",
      "Validation Recall: 0.7395833333333334\n",
      "Validation F1: 0.663551401869159\n",
      "Validation Accuracy: 0.6269430051813472\n",
      "---------------------------------------------------------------------------\n",
      "Features: 25000, Current Fold: 5, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6050420168067226\n",
      "Validation Recall: 0.75\n",
      "Validation F1: 0.669767441860465\n",
      "Validation Accuracy: 0.6302083333333334\n",
      "---------------------------------------------------------------------------\n",
      "Features: 25000, Current Fold: 6, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6302521008403361\n",
      "Validation Recall: 0.78125\n",
      "Validation F1: 0.6976744186046512\n",
      "Validation Accuracy: 0.6614583333333334\n",
      "---------------------------------------------------------------------------\n",
      "Features: 25000, Current Fold: 7, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6964285714285714\n",
      "Validation Recall: 0.8125\n",
      "Validation F1: 0.75\n",
      "Validation Accuracy: 0.7291666666666666\n",
      "---------------------------------------------------------------------------\n",
      "Features: 25000, Current Fold: 8, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6545454545454545\n",
      "Validation Recall: 0.75\n",
      "Validation F1: 0.6990291262135923\n",
      "Validation Accuracy: 0.6770833333333334\n",
      "---------------------------------------------------------------------------\n",
      "Features: 25000, Current Fold: 9, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.69\n",
      "Validation Recall: 0.71875\n",
      "Validation F1: 0.7040816326530612\n",
      "Validation Accuracy: 0.6979166666666666\n",
      "---------------------------------------------------------------------------\n",
      "Features: 25000, Current Fold: 10, depth 5, estimators 100\n",
      "---------------------------------------------------------------------------\n",
      "Validation Precision: 0.6442307692307693\n",
      "Validation Recall: 0.6979166666666666\n",
      "Validation F1: 0.67\n",
      "Validation Accuracy: 0.65625\n",
      "---------------------------------------------------------------------------\n",
      "Stratified k-fold: Random Forest with 25000 features, depth 5, estimators 100\n",
      "Avg Validation Precision: 0.6532796004029581\n",
      "Avg Validation Recall: 0.7536512027491409\n",
      "Avg Validation F1: 0.6993624737033487\n",
      "Avg Validation Accuracy: 0.6756746545768567\n",
      "---------------------------------------------------------------------------\n",
      "Total running time = 267.32 seconds\n"
     ]
    }
   ],
   "source": [
    "dataset_tfidf, labels = readmission_30day_tfidf, readmission_30day_labels\n",
    "train_validate_randomForest(dataset_tfidf, labels, n_splits=KFOLD_SPLITS, shuffle=True, estimators=100, depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Chi-squared based Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1) Select Correctly Identified Positive Samples from CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4563,)\n",
      "torch.Size([4563])\n",
      "(1199,)\n",
      "torch.Size([1199])\n"
     ]
    }
   ],
   "source": [
    "# General readmissions correctly predicted by CNN\n",
    "tokens_gen = np.concatenate(tokens_list_gen, axis=0)\n",
    "sample_labels_gen = torch.hstack(sample_labels_list_gen)\n",
    "\n",
    "print(tokens_gen.shape)\n",
    "print(sample_labels_gen.shape)\n",
    "\n",
    "# 30 day readmissions correctly predicted by CNN\n",
    "tokens_30day = np.concatenate(tokens_list_30day, axis=0)\n",
    "sample_labels_30day = torch.hstack(sample_labels_list_30day)\n",
    "\n",
    "print(tokens_30day.shape)\n",
    "print(sample_labels_30day.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2) Find Top 20 Features from Correct Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4563, 63830)\n",
      "(1199, 33284)\n"
     ]
    }
   ],
   "source": [
    "# General readmissions correctly predicted by CNN\n",
    "vectorizer_count_gen = CountVectorizer(tokenizer=return_original, preprocessor=return_original)\n",
    "X_train_count_gen = vectorizer_count_gen.fit_transform(tokens_gen)\n",
    "print(X_train_count_gen.shape)\n",
    "\n",
    "# 30 day readmissions correctly predicted by CNN\n",
    "vectorizer_count_30day = CountVectorizer(tokenizer=return_original, preprocessor=return_original)\n",
    "X_train_count_30day = vectorizer_count_30day.fit_transform(tokens_30day)\n",
    "print(X_train_count_30day.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4563, 20)\n",
      "(1199, 20)\n"
     ]
    }
   ],
   "source": [
    "# General readmissions correctly predicted by CNN\n",
    "chi2_model_count_gen = SelectKBest(chi2, k=20)\n",
    "X_new_count_gen = chi2_model_count_gen.fit_transform(X_train_count_gen, sample_labels_gen)\n",
    "print(X_new_count_gen.shape)\n",
    "\n",
    "# 30 day readmissions correctly predicted by CNN\n",
    "chi2_model_count_30day = SelectKBest(chi2, k=20)\n",
    "X_new_count_30day = chi2_model_count_30day.fit_transform(X_train_count_30day, sample_labels_30day)\n",
    "print(X_new_count_30day.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['capsule' 'chewable' 'chronic' 'daily' 'date/time' 'day' 'dialysis'\n",
      " 'every' 'expired' 'hd' 'inhalation' 'insulin' 'mg' 'needed' 'one' 'po'\n",
      " 'provider' 'sig' 'tablet' 'times']\n",
      "['blood' 'capsule' 'daily' 'day' 'every' 'expired' 'hd' 'inhalation'\n",
      " 'last' 'mg' 'ml' 'name' 'needed' 'one' 'p.o' 'po' 'sig' 'tablet' 'tid'\n",
      " 'times']\n"
     ]
    }
   ],
   "source": [
    "# General readmissions correctly predicted by CNN\n",
    "feature_names_count_gen = vectorizer_count_gen.get_feature_names_out()\n",
    "feature_names_count_gen = feature_names_count_gen[chi2_model_count_gen.get_support()]\n",
    "print(feature_names_count_gen)\n",
    "\n",
    "# 30 day readmissions correctly predicted by CNN\n",
    "feature_names_count_30day = vectorizer_count_30day.get_feature_names_out()\n",
    "feature_names_count_30day = feature_names_count_30day[chi2_model_count_30day.get_support()]\n",
    "print(feature_names_count_30day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopChi2Features(tokens, sample_labels, chi2_model, feature_names_count, tokenizer=return_original, preprocessor=return_original):\n",
    "    # Positive sample counts\n",
    "    pos_vectorizer_count = CountVectorizer(tokenizer=tokenizer, preprocessor=preprocessor)\n",
    "    pos_X_train_count = pos_vectorizer_count.fit_transform(tokens[sample_labels == 1])\n",
    "    pos_counts = pd.DataFrame(np.sum(pos_X_train_count, axis=0), columns=pos_vectorizer_count.get_feature_names_out())\n",
    "    print(\"Positive count: \", pos_X_train_count.shape)\n",
    "\n",
    "    # Negative sample counts\n",
    "    neg_vectorizer_count = CountVectorizer(tokenizer=tokenizer, preprocessor=preprocessor)\n",
    "    neg_X_train_count = neg_vectorizer_count.fit_transform(tokens[sample_labels == 0])\n",
    "    neg_counts = pd.DataFrame(np.sum(neg_X_train_count, axis=0), columns=neg_vectorizer_count.get_feature_names_out())\n",
    "    print(\"Negative count: \", neg_X_train_count.shape)\n",
    "\n",
    "    # Get counts for each\n",
    "    feature_scores = chi2_model.scores_[chi2_model.get_support()]\n",
    "    top_counts = [(word, score.round(2), pos_counts[word][0], neg_counts[word][0]) for word, score in zip(feature_names_count, feature_scores)]\n",
    "    top_counts.sort(key=lambda x: -(x[1]))\n",
    "    print(\"Word, Score, Positive Sample Count, Negative Sample Count\")\n",
    "    for word_count in top_counts:\n",
    "        print(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive count:  (2289, 44522)\n",
      "Negative count:  (2274, 43312)\n",
      "Word, Score, Positive Sample Count, Negative Sample Count\n",
      "('tablet', 5602.05, 44844, 24855)\n",
      "('sig', 4701.55, 28473, 14173)\n",
      "('mg', 4300.27, 42891, 25515)\n",
      "('po', 3527.43, 33243, 19438)\n",
      "('one', 3238.99, 25303, 13905)\n",
      "('daily', 2553.22, 29552, 18337)\n",
      "('day', 2047.19, 22255, 13573)\n",
      "('expired', 1336.95, 6, 1346)\n",
      "('capsule', 1290.66, 7766, 3855)\n",
      "('times', 1195.63, 9160, 4999)\n",
      "('every', 1148.57, 7564, 3898)\n",
      "('hd', 1030.33, 2651, 764)\n",
      "('dialysis', 884.47, 1920, 461)\n",
      "('date/time', 864.15, 2199, 627)\n",
      "('insulin', 855.23, 3799, 1627)\n",
      "('chewable', 839.38, 2068, 571)\n",
      "('chronic', 817.53, 5852, 3115)\n",
      "('needed', 808.1, 7134, 4086)\n",
      "('provider', 752.39, 2258, 745)\n",
      "('inhalation', 685.86, 2383, 877)\n"
     ]
    }
   ],
   "source": [
    "getTopChi2Features(tokens_gen, sample_labels_gen, chi2_model_count_gen, feature_names_count_gen, tokenizer=return_original, preprocessor=return_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive count:  (600, 25506)\n",
      "Negative count:  (599, 20906)\n",
      "Word, Score, Positive Sample Count, Negative Sample Count\n",
      "('tablet', 2776.03, 12860, 5672)\n",
      "('sig', 2177.17, 8320, 3284)\n",
      "('po', 1862.83, 9893, 4672)\n",
      "('daily', 1692.19, 9093, 4318)\n",
      "('mg', 1527.41, 11608, 6355)\n",
      "('one', 1407.81, 7285, 3398)\n",
      "('needed', 626.09, 2306, 889)\n",
      "('every', 615.03, 2343, 923)\n",
      "('capsule', 608.58, 2224, 853)\n",
      "('day', 605.19, 6012, 3593)\n",
      "('blood', 495.38, 7660, 5132)\n",
      "('name', 458.1, 6547, 4308)\n",
      "('hd', 455.06, 769, 129)\n",
      "('times', 382.15, 2496, 1290)\n",
      "('p.o', 370.15, 191, 794)\n",
      "('expired', 362.65, 2, 368)\n",
      "('ml', 357.83, 1097, 371)\n",
      "('inhalation', 355.57, 781, 192)\n",
      "('tid', 339.58, 1105, 391)\n",
      "('last', 321.09, 4732, 3136)\n"
     ]
    }
   ],
   "source": [
    "getTopChi2Features(tokens_30day, sample_labels_30day, chi2_model_count_30day, feature_names_count_30day, tokenizer=return_original, preprocessor=return_original)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
